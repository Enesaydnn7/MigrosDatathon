{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../organized_data/train_cleaned_v1.csv')\n",
    "test = pd.read_csv('../organized_data/test_organized.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "individualnumber\n",
      "\n",
      "[94230288  4684087 88026681 ... 98445787 13781030 96703898]\n",
      "\n",
      "\n",
      "category_number\n",
      "\n",
      "[9000 9030 9001 9046 9044 9007 9006 9022 9018 9038 9058 9049 9042 9029\n",
      " 9036 9024 9032 9056 9043 9010 9002 9059 9004 9037 9055 9019 9031 9035\n",
      " 9012 9054 9009 9040 9027 9021 9048 9017 9052 9039 9003 9005 9060 9015\n",
      " 9008 9041 9020 9053 9061 9028 9011]\n",
      "\n",
      "\n",
      "hakkedis_amt\n",
      "\n",
      "[ 21.  17.  22.  38.  85.  27.  19.  33.  60.  43.  16.  23.  56.   9.\n",
      "  24.  26.  32.  18.  39.  66.  57.  55.  45.  49.  15.  40.  28.  34.\n",
      "  99.  20.  36.  37. 100. 121.  30.  35.  48.  41.  31.  78.   7.  44.\n",
      "  14. 104.  73.  54.  90.  51.  52.  11.  63.   8.  79.  72.  29.  42.\n",
      "  80.  77.  12.  71.  10. 125.  92.  25.  68.  69.  13. 136.  47.  65.\n",
      "  62.  46.  70.  96.  67.  64.  50.  97. 118.  59. 112. 105.  83.  76.\n",
      "  58.  53.  91.  75.  74. 109.  84.  93.  95. 123. 135. 116. 126. 113.\n",
      "  94. 129. 131. 107. 180. 114. 111. 119. 122. 117. 115. 102.  87. 124.\n",
      "  61. 120.  81.  89. 106. 103. 128. 108. 110.]\n",
      "\n",
      "\n",
      "odul_amt\n",
      "\n",
      "[ 2.  1.  3.  8.  6.  4.  5. 14. 10. 12.  7.  9. 20. 13. 11. 15. 18. 16.\n",
      " 17. 19.]\n",
      "\n",
      "\n",
      "response\n",
      "\n",
      "[0 1]\n",
      "\n",
      "\n",
      "total_money_spent\n",
      "\n",
      "[ 7118.94741 10192.64563 11559.66676 ...  2432.60788  1242.70635\n",
      "    37.1    ]\n",
      "\n",
      "\n",
      "total_discount\n",
      "\n",
      "[1.77489978e+02 3.19072605e+04 2.31976316e+02 ... 5.00344604e+02\n",
      " 2.44758629e+02 6.08045220e+00]\n",
      "\n",
      "\n",
      "sanal_percent\n",
      "\n",
      "[0.015625   0.         0.95       0.14285714 0.42857143 0.13333333\n",
      " 0.4        0.05882353 0.5        0.07692308 0.9375     0.1\n",
      " 0.0212766  0.33333333 1.         0.51162791 0.625      0.97058824\n",
      " 0.04166667 0.03921569 0.2189781  0.48684211 0.14516129 0.24324324\n",
      " 0.00892857 0.10447761 0.51428571 0.00114286 0.01515152 0.01351351\n",
      " 0.27777778 0.02941176 0.06081081 0.23529412 0.37142857 0.03030303\n",
      " 0.2375     0.16666667 0.18518519 0.28571429 0.26213592 0.02857143\n",
      " 0.05940594 0.03571429 0.03846154 0.375      0.33928571 0.34615385\n",
      " 0.88235294 0.00877193 0.53846154 0.26666667 0.01666667 0.55555556\n",
      " 0.11111111 0.10526316 0.56818182 0.31360947 0.38461538 0.06666667\n",
      " 0.98461538 0.80392157 0.09638554 0.10169492 0.05263158 0.35185185\n",
      " 0.7826087  0.69354839 0.44       0.03333333 0.55932203 0.08333333\n",
      " 0.02040816 0.05555556 0.80487805 0.025      0.3974359  0.2\n",
      " 0.02564103 0.84615385 0.68595041 0.03125    0.0052356  0.03529412\n",
      " 0.75       0.27102804 0.29787234 0.86567164 0.21052632 0.38709677\n",
      " 0.01010101 0.14       0.13888889 0.97297297 0.03225806 0.30952381\n",
      " 0.72727273 0.81818182 0.11904762 0.98701299 0.00680272 0.66666667\n",
      " 0.92592593 0.03703704 0.68965517 0.13235294 0.93103448 0.05\n",
      " 0.20930233 0.07142857 0.83333333 0.18181818 0.31325301 0.01886792\n",
      " 0.09552239 0.14705882 0.175      0.45       0.70588235 0.13793103\n",
      " 0.00980392 0.04929577 0.35       0.04054054 0.3814433  0.27272727\n",
      " 0.13636364 0.03289474 0.45882353 0.09090909 0.63333333 0.12195122\n",
      " 0.21153846 0.02597403 0.01960784 0.37037037 0.02739726 0.25\n",
      " 0.73873874 0.0078125  0.06976744 0.125      0.02439024 0.02702703\n",
      " 0.45454545 0.36538462 0.12       0.02526316 0.54545455 0.57894737\n",
      " 0.32786885 0.29807692 0.00735294 0.57142857 0.31147541 0.01851852\n",
      " 0.14473684 0.31506849 0.74305556 0.10833333 0.08       0.05714286\n",
      " 0.6        0.05405405 0.29310345 0.53333333 0.01923077 0.92929293\n",
      " 0.0625     0.04255319 0.30612245 0.61313869 0.64285714 0.03870968\n",
      " 0.02272727 0.03278689 0.52631579 0.73469388 0.00675676 0.71428571\n",
      " 0.12903226 0.12121212 0.56410256 0.09230769 0.52380952 0.00970874\n",
      " 0.35294118 0.91666667 0.01818182 0.97674419 0.07407407 0.12244898\n",
      " 0.09433962 0.98412698 0.17307692 0.10144928 0.02238806 0.00571429\n",
      " 0.56       0.17241379 0.0989011  0.35714286 0.01470588 0.01282051\n",
      " 0.15942029 0.41558442 0.02538071 0.02325581 0.140625   0.3125\n",
      " 0.01234568 0.03676471 0.08695652 0.85714286 0.01020408 0.02352941\n",
      " 0.82857143 0.13740458 0.9        0.31666667 0.73809524 0.02158273\n",
      " 0.53061224 0.43137255 0.03448276 0.11956522 0.19047619 0.50649351\n",
      " 0.00769231 0.13461538 0.19148936 0.37662338 0.58333333 0.88888889\n",
      " 0.65853659 0.31034483 0.84375    0.90909091 0.94736842 0.01587302\n",
      " 0.04761905 0.73684211 0.11428571 0.13043478 0.89473684 0.65217391\n",
      " 0.1875     0.04285714 0.26923077 0.1965812  0.06315789 0.1980198\n",
      " 0.31764706 0.0375     0.03816794 0.32222222 0.44094488 0.00630252\n",
      " 0.5106383  0.97368421 0.12222222 0.575      0.00952381 0.54166667\n",
      " 0.74509804 0.76785714 0.07865169 0.13953488 0.875      0.01785714\n",
      " 0.04545455 0.59210526 0.99137931 0.15789474 0.93714286 0.71171171\n",
      " 0.02173913 0.34375    0.73863636 0.06779661 0.8        0.01711027\n",
      " 0.15384615 0.59322034 0.47058824 0.00775194 0.02631579 0.16129032\n",
      " 0.04347826 0.02906977 0.0035461  0.00289436 0.07066052 0.04950495\n",
      " 0.06451613 0.23076923 0.71052632 0.01333333 0.31746032 0.68571429\n",
      " 0.07462687 0.02898551 0.59259259 0.01315789 0.03370787 0.76229508\n",
      " 0.17647059 0.00268097 0.07272727 0.02764977 0.06382979 0.85263158\n",
      " 0.04938272 0.37931034 0.94444444 0.68181818 0.02       0.17948718\n",
      " 0.22222222 0.81958763 0.01680672 0.23809524 0.08064516 0.89265537\n",
      " 0.86363636 0.765625   0.00286533 0.26804124 0.29032258 0.80645161\n",
      " 0.075      0.184      0.25242718 0.47368421 0.01801802 0.13432836\n",
      " 0.15625    0.84210526 0.3        0.72972973 0.00990099 0.25925926\n",
      " 0.02083333 0.1986755  0.03174603 0.44444444 0.66       0.24561404\n",
      " 0.63565891 0.04477612 0.38655462 0.72131148 0.51219512 0.02409639\n",
      " 0.04580153 0.41666667 0.23741007 0.0125     0.24193548 0.109375\n",
      " 0.25714286 0.00810811 0.15       0.04       0.03592814 0.79761905\n",
      " 0.19402985 0.03624733 0.63934426 0.05952381 0.24528302 0.54032258\n",
      " 0.10714286 0.81896552 0.48       0.06896552 0.04444444 0.00181818\n",
      " 0.67368421 0.11764706 0.00460829 0.61538462 0.04790419 0.40972222\n",
      " 0.02808989 0.09375    0.00806452 0.3853211  0.86666667 0.06060606\n",
      " 0.45333333 0.9516129  0.98360656 0.01606426 0.80555556 0.12820513\n",
      " 0.15909091 0.71875    0.15151515 0.55633803 0.09859155 0.046875\n",
      " 0.01449275 0.69230769 0.21917808 0.08163265 0.22543353 0.30769231\n",
      " 0.10810811 0.41605839 0.00961538 0.02777778 0.97794118 0.00518135\n",
      " 0.92307692 0.00451467 0.53191489 0.225      0.01869159 0.06363636\n",
      " 0.2745098  0.41216216 0.50295858 0.4751773  0.51973684 0.35483871\n",
      " 0.92857143 0.78787879 0.13821138 0.83478261 0.00862069 0.55882353\n",
      " 0.11038961 0.14893617 0.2345679  0.08910891 0.97619048 0.38571429\n",
      " 0.77310924 0.3220339  0.01369863 0.1025641  0.00327869 0.60714286\n",
      " 0.05494505 0.58823529 0.336      0.45652174 0.32       0.26315789\n",
      " 0.63829787 0.18867925 0.01226994 0.20212766 0.07894737 0.77777778\n",
      " 0.89830508 0.44230769 0.7032967  0.00763359 0.15254237 0.40909091\n",
      " 0.07936508 0.01298701 0.95833333 0.01980198 0.01639344 0.00205339\n",
      " 0.45945946 0.00653595 0.30107527 0.53571429 0.00684932 0.09215017\n",
      " 0.31111111 0.76923077 0.01302083 0.18032787 0.30508475 0.26785714\n",
      " 0.10784314 0.78947368 0.30434783 0.7761194  0.17073171 0.1038961\n",
      " 0.02380952 0.39130435 0.46153846 0.91428571 0.51851852 0.38\n",
      " 0.09146341 0.00900901 0.03409091 0.62857143 0.24576271 0.95238095\n",
      " 0.31818182 0.02150538 0.12621359 0.41304348 0.89361702 0.14117647\n",
      " 0.0952381  0.2244898  0.01612903 0.64646465 0.71590909 0.00549451\n",
      " 0.24590164 0.03389831 0.003663   0.76470588 0.39473684 0.14754098\n",
      " 0.00515464 0.01111111 0.3877551  0.62318841 0.13157895 0.91509434\n",
      " 0.07843137 0.06578947 0.19565217 0.36842105 0.44047619 0.97761194\n",
      " 0.05487805 0.28358209 0.25641026 0.00636943 0.39393939 0.00429799\n",
      " 0.63265306 0.32653061 0.46666667 0.83018868 0.17391304 0.50420168\n",
      " 0.47080292 0.26285714 0.90625    0.29166667 0.02531646 0.09677419\n",
      " 0.59090909 0.21428571 0.1754386  0.01263158 0.02112676 0.64705882\n",
      " 0.52941176 0.00869565 0.34090909 0.40625    0.60810811 0.7\n",
      " 0.01538462 0.18421053 0.77083333 0.01265823 0.00621118 0.24444444\n",
      " 0.10638298 0.67625899 0.79850746 0.37333333 0.03669725 0.55172414\n",
      " 0.18085106 0.11538462 0.63636364 0.07608696 0.00444444 0.1942446\n",
      " 0.14659686 0.29411765 0.10204082 0.86206897 0.0546875  0.03883495\n",
      " 0.67149758 0.152      0.69565217 0.31578947 0.00492611 0.76190476\n",
      " 0.09401709 0.0483871  0.1627907  0.46268657 0.56060606 0.27868852\n",
      " 0.27710843 0.796875   0.99038462 0.53246753 0.83809524 0.0326087\n",
      " 0.74666667 0.17045455 0.96428571 0.05128205 0.02222222 0.00595238\n",
      " 0.20588235 0.08724832 0.45833333 0.00714286 0.72413793 0.01408451\n",
      " 0.31707317 0.30379747 0.25581395 0.25333333 0.985      0.61783439\n",
      " 0.82882883 0.96116505 0.64367816 0.26582278 0.16       0.42307692\n",
      " 0.0388601  0.06504065 0.89       0.40217391 0.00224215 0.09248555\n",
      " 0.60576923 0.24390244 0.01       0.55       0.44642857 0.2016129\n",
      " 0.63157895 0.02954545 0.6875     0.01754386 0.85057471 0.03076923\n",
      " 0.14606742 0.87755102 0.04081633 0.03       0.5625     0.30392157\n",
      " 0.57594937 0.25742574 0.04145078 0.6119403  0.17156863 0.01428571\n",
      " 0.21111111 0.00699301 0.16748768 0.63247863 0.01041667 0.03191489\n",
      " 0.24137931 0.2804878  0.85483871 0.4375     0.03773585 0.81538462\n",
      " 0.08641975 0.39622642 0.00454545 0.12307692 0.12048193 0.22857143\n",
      " 0.57575758 0.40983607 0.42592593 0.58730159 0.65714286 0.01098901\n",
      " 0.69402985 0.0297619  0.42567568 0.30263158 0.41176471 0.43181818\n",
      " 0.4893617  0.67741935 0.65648855 0.8125     0.87586207 0.05347594\n",
      " 0.72277228 0.61333333 0.03472222 0.01052632 0.19354839 0.93333333\n",
      " 0.04615385 0.17142857 0.10344828 0.02479339 0.22727273 0.13114754\n",
      " 0.16363636 0.24615385 0.02247191 0.7027027  0.04878049 0.38235294\n",
      " 0.34782609 0.2173913  0.95762712 0.01190476 0.55813953 0.10852713\n",
      " 0.00649351 0.62878788 0.00358423 0.01492537 0.69090909 0.11176471\n",
      " 0.34939759 0.29113924 0.07317073 0.87878788 0.04651163 0.52054795\n",
      " 0.915625   0.64       0.53030303 0.14130435 0.11363636 0.02816901\n",
      " 0.36363636 0.56896552 0.08823529 0.79259259 0.03623188 0.87168142\n",
      " 0.96226415 0.24074074 0.37704918 0.05797101 0.00609756 0.97222222\n",
      " 0.74418605 0.0038835  0.06493506 0.61940299 0.83892617 0.98765432\n",
      " 0.04132231 0.59036145 0.00845666 0.0960452  0.43243243 0.02586207\n",
      " 0.73170732 0.01030928 0.81081081 0.76271186 0.06944444 0.32105263\n",
      " 0.54054054 0.04411765 0.08130081 0.62222222 0.16161616 0.12941176\n",
      " 0.73333333 0.14084507 0.32989691 0.08571429 0.15646259 0.65\n",
      " 0.5862069  0.70238095 0.06097561 0.36666667 0.02985075 0.51748252\n",
      " 0.72321429 0.00497512 0.51282051 0.05763689 0.98039216 0.66037736\n",
      " 0.01150895 0.42553191 0.10465116 0.06       0.40828402 0.16883117\n",
      " 0.825      0.07971014 0.68       0.06818182 0.16393443 0.02061856\n",
      " 0.08411215 0.43902439 0.31481481 0.01213172 0.01709402 0.07792208\n",
      " 0.74647887 0.23684211 0.62037037 0.05194805 0.3015873  0.58064516\n",
      " 0.19298246 0.24242424 0.80769231 0.35064935 0.09302326 0.56470588\n",
      " 0.54716981 0.57352941 0.99350649 0.02053388 0.79245283 0.67226891\n",
      " 0.04891304 0.00943396 0.09322034 0.42424242 0.94117647 0.73\n",
      " 0.36263736 0.96825397 0.05769231 0.42105263 0.01459854 0.0862069\n",
      " 0.1369863  0.06508876 0.27433628 0.925      0.57446809 0.30588235\n",
      " 0.47619048 0.00988142]\n",
      "\n",
      "\n",
      "shop_count\n",
      "\n",
      "[ 64.  30.  40.   4.   6.  94.  25. 148.   3.  11.  16.   1.   2.  37.\n",
      "  29.   8.  17.  28.  63. 165.  33. 315.  32.  76.   7.  88.  26.  15.\n",
      "  81.  36.  71.  13.  90.   5.  48.  21. 210.  10.  23.  47.  41.  49.\n",
      "  22. 111. 121.  39.   9.  67.  43.  20.  12.  14.  34.  27.  24.  51.\n",
      " 137.  78.  54.  62.  69.  19.  31. 112.  35.  85. 875.  66.  74.  18.\n",
      " 182. 351.  68.  50.  70. 107.  91.  52. 123.  59. 120.  80.  73.  42.\n",
      " 103. 114.  83. 101.  57.  53.  56.  60.  44. 169.  61.  99.  46. 203.\n",
      "  65.  38. 159. 237. 172.  82. 128.  98. 131. 150. 637.  55. 127. 108.\n",
      " 110.  75. 242. 191. 125. 185. 145.  93. 132.  77.  79. 147. 287. 106.\n",
      " 454.  58. 154. 171. 380.  95. 601. 335. 329.  87. 142. 115. 160. 135.\n",
      "  92. 102.  97.  72. 152. 116. 129. 215. 155. 475. 146. 178.  86. 100.\n",
      " 104. 124. 238. 136. 144. 166. 149.  84.  96. 162. 503. 133. 119. 138.\n",
      " 134. 175. 139. 122. 176. 197. 161. 143. 233. 362. 193. 188. 140. 130.\n",
      " 225. 180. 173.  45. 682. 126. 285. 205. 117. 476. 255. 813. 168. 105.\n",
      "  89. 500. 153. 265. 231. 200. 526. 516. 282. 691. 651. 520. 109. 373.\n",
      " 222. 164. 217. 232. 141. 163. 194. 177. 438. 349. 439. 866. 209. 118.\n",
      " 440. 151. 113. 156. 370. 216. 167. 469. 219. 181. 550. 158. 249. 334.\n",
      " 371. 262. 348. 443. 325. 296. 823. 224. 305. 223. 321. 254. 487. 306.\n",
      " 293. 384. 322. 189. 228. 358. 170. 240. 273. 211. 302. 486. 248. 204.\n",
      " 336. 157. 698. 327. 421. 274. 284. 390. 435. 272. 491. 338. 207. 478.\n",
      " 368. 504. 190. 386. 378. 749. 196. 446. 826. 519. 269. 183. 320. 234.\n",
      " 220. 187. 235. 522. 268. 313. 568. 275. 266. 199. 697. 241. 279. 481.\n",
      " 258. 201. 474. 548. 276. 226. 515. 473. 195. 414. 411. 512. 738. 355.\n",
      " 347. 629. 782. 244. 577. 174. 703. 184. 397. 415. 573. 506.]\n",
      "\n",
      "\n",
      "months_since_last_shopping\n",
      "\n",
      "[ 1.  3.  2.  5.  4.  7.  9. 10.  6. 11.  8. 12.]\n",
      "\n",
      "\n",
      "days_shopped\n",
      "\n",
      "[357. 309. 350. 188.  94. 362. 332. 364.  34. 210. 347.   1.  15. 349.\n",
      " 326. 341. 356. 149. 328.  79. 353. 346. 150. 153. 365. 276.  93.  22.\n",
      " 337. 310. 227. 359. 206. 293. 166.  57. 208. 247.   3. 228. 360. 284.\n",
      "  25. 138. 251. 191.  63. 249. 244.  92. 361. 265.  29.  10. 109. 148.\n",
      " 303. 298. 114. 213. 338.  95. 275. 250. 112. 307.  40. 241. 315. 230.\n",
      " 202. 218. 297. 178. 103. 324. 281. 279. 343. 342. 115. 120. 135. 124.\n",
      "  98. 300. 212. 355. 306. 312. 182. 363. 352. 334.  36.  16. 302. 348.\n",
      " 323.  74.  59. 321. 125. 142. 339. 200. 162. 219.  11. 314. 351.  49.\n",
      " 333.  50.  37. 253. 179. 118. 344. 358. 144. 232. 345. 316. 366. 329.\n",
      "  76. 185. 224.  53. 197. 282.  99. 221. 325. 122. 105. 139.   8. 288.\n",
      " 132. 320. 165. 331.  56. 313. 283.   5. 167.  80. 308. 327. 294. 126.\n",
      " 236. 340. 146. 246. 195. 239. 271. 257.  89. 254. 273. 262. 268. 143.\n",
      " 155. 267. 274. 264. 292. 289. 217. 181.  90.  45. 256. 285. 176. 336.\n",
      " 354. 123. 145. 169. 237.  83. 304. 215. 175. 101. 295. 111. 116. 318.\n",
      " 305. 136.  86. 335. 240. 269.  48.  84.  44. 233.  78. 154. 151.   9.\n",
      " 322. 234.  31.  97. 117. 211. 189. 164. 223. 290.  38. 263.  81. 242.\n",
      " 266. 311. 203.  18.  70.  68.  30. 272. 317.  96.  26.   2. 171.  39.\n",
      " 207. 180.   6. 238.   7.  28. 226.  82. 258. 301. 194. 259.  62. 127.\n",
      " 296. 270. 204. 209. 287. 172.  65.  24. 319.  55. 330. 163.  54. 133.\n",
      " 220. 174.  75.   4. 291. 280.  12.  58.  43. 229. 261. 214. 196.  14.\n",
      " 131. 231.  33.  17. 245. 186. 184. 277.  41. 205. 177.  20. 193. 286.\n",
      "  72. 161.  64.  66. 107.  47. 260. 156. 299. 199. 113.  85. 235. 141.\n",
      " 201. 216. 147.  60. 183. 134. 248. 225. 121. 278.  51. 102.  23. 198.\n",
      "  77. 252. 170. 129. 160.  35. 110. 130. 106. 100.  42. 243. 119. 192.\n",
      "  87. 168. 104.  69.  71.  88. 128.  13. 222.  61.  67. 190.  21.  52.\n",
      "  73. 108. 187. 152. 140. 255.  32.  19.  46. 137. 159. 157. 173. 158.\n",
      "  91.  27.]\n",
      "\n",
      "\n",
      "gender\n",
      "\n",
      "['E' 'K' nan]\n",
      "\n",
      "\n",
      "city_code\n",
      "\n",
      "[ 7. 19. 34.  9. 46. 35. 10. 16. 23.  1. 57.  5. 31. 52. 54.  6.  4. 27.\n",
      " 38. 24. 55. 22. 77. 20. 33. 21. 17. 80. 70. 45. 61. 59. 50. 72. 43. 41.\n",
      " 42. 25. 58. 39. 67. 56. 26.  2. 66. 64. 71. 11. 48. 32. 74. 47. 15. 78.\n",
      " 60. 28. 69.  3. 63. 65. 40. 51. 37. 13. 36. 81. 53. 44. 76. 12. 68. 14.\n",
      " 18. 29. 79. 30. 62. 49. 73. 75.  8. 99.]\n",
      "\n",
      "\n",
      "age\n",
      "\n",
      "[39. 71. 61. 38. 23. 68. 40. 36. 67. 65. 27. 49. 31. 21. 37. 22. 62. 42.\n",
      " 29. 63. 44. 48. 46. 20. 45. 33. 43. 58. 52. 25. 32. 41. 66. 54. 30. 24.\n",
      " 60. 26. 59. 56. 19. 55. 28. 35. 51. 57. 64. 50. 34. 75. 47. 69. 53. 77.\n",
      " 74. 70. 72. 78. 86. 73. 81. 79. 92. 80. 82. 87. 76. 88. 83. 84. 85. 89.\n",
      " 98. 96. 91. 93. 90.]\n",
      "\n",
      "\n",
      "level1_relevant_category_volume\n",
      "\n",
      "[996.749 461.227 308.15  ... 473.77  408.99  168.546]\n",
      "\n",
      "\n",
      "level2_relevant_category_volume\n",
      "\n",
      "[487.36  105.9   138.65  ...  84.81   99.416  68.5  ]\n",
      "\n",
      "\n",
      "level3_relevant_category_volume\n",
      "\n",
      "[241.11  105.9   138.65  ...  84.81   27.656  68.5  ]\n",
      "\n",
      "\n",
      "level4_relevant_category_volume\n",
      "\n",
      "[241.11  105.9   138.65  ... 157.9    27.656  68.5  ]\n",
      "\n",
      "\n",
      "level1_relevant_category_quantity\n",
      "\n",
      "[96.72  35.08  14.    ... 72.157 43.05  10.832]\n",
      "\n",
      "\n",
      "level2_relevant_category_quantity\n",
      "\n",
      "[47.    12.     8.    ... 85.21   0.102  3.832]\n",
      "\n",
      "\n",
      "level3_relevant_category_quantity\n",
      "\n",
      "[36.    12.     8.    ... 72.21   0.102  0.832]\n",
      "\n",
      "\n",
      "level4_relevant_category_quantity\n",
      "\n",
      "[36.    12.     8.    ... 72.21   0.102  0.832]\n",
      "\n",
      "\n",
      "level1_relevant_category_volume_per_day\n",
      "\n",
      "[2.79201401 1.49264401 0.88042857 ... 0.47211765 0.20266272 0.08175966]\n",
      "\n",
      "\n",
      "level2_relevant_category_volume_per_day\n",
      "\n",
      "[1.36515406 0.34271845 0.39614286 ... 0.27847619 0.20266272 0.0555794 ]\n",
      "\n",
      "\n",
      "level3_relevant_category_volume_per_day\n",
      "\n",
      "[0.67537815 0.34271845 0.39614286 ... 0.07746779 0.20266272 0.0472103 ]\n",
      "\n",
      "\n",
      "level4_relevant_category_volume_per_day\n",
      "\n",
      "[0.67537815 0.34271845 0.39614286 ... 0.07746779 0.20266272 0.0472103 ]\n",
      "\n",
      "\n",
      "level1_relevant_category_quantity_per_day\n",
      "\n",
      "[0.27092437 0.11352751 0.04       ... 0.04775281 0.19657534 0.03034174]\n",
      "\n",
      "\n",
      "level2_relevant_category_quantity_per_day\n",
      "\n",
      "[0.13165266 0.03883495 0.02285714 ... 0.07022472 0.16438356 0.01073389]\n",
      "\n",
      "\n",
      "level3_relevant_category_quantity_per_day\n",
      "\n",
      "[0.10084034 0.03883495 0.02285714 ... 0.04863222 0.12785388 0.00233053]\n",
      "\n",
      "\n",
      "level4_relevant_category_quantity_per_day\n",
      "\n",
      "[0.10084034 0.03883495 0.02285714 ... 0.07022472 0.12785388 0.00233053]\n",
      "\n",
      "\n",
      "total_money_spent_per_day\n",
      "\n",
      "[19.94102916 32.98590819 33.02761931 ...  6.81402768  3.67664601\n",
      "  0.15922747]\n",
      "\n",
      "\n",
      "discount_per_day\n",
      "\n",
      "[4.97170807e-01 1.03259743e+02 6.62789475e-01 ... 1.49356598e+00\n",
      " 6.85598399e-01 1.79895036e-02]\n",
      "\n",
      "\n",
      "odul/hakkedis\n",
      "\n",
      "[0.0952381  0.05882353 0.09090909 0.07894737 0.09411765 0.07407407\n",
      " 0.05263158 0.1        0.09302326 0.0625     0.08695652 0.08928571\n",
      " 0.11111111 0.13043478 0.08333333 0.07692308 0.09375    0.05555556\n",
      " 0.14035088 0.13333333 0.14285714 0.08163265 0.06666667 0.07142857\n",
      " 0.08823529 0.14141414 0.08108108 0.09917355 0.08571429 0.09756098\n",
      " 0.09677419 0.08974359 0.13636364 0.09615385 0.09589041 0.09259259\n",
      " 0.09803922 0.08888889 0.125      0.08860759 0.14634146 0.13888889\n",
      " 0.06896552 0.09859155 0.096      0.09782609 0.12       0.12121212\n",
      " 0.08       0.14705882 0.08510638 0.09230769 0.14545455 0.14814815\n",
      " 0.09558824 0.13953488 0.14925373 0.13793103 0.13513514 0.140625\n",
      " 0.13157895 0.09278351 0.14       0.13846154 0.09322034 0.08474576\n",
      " 0.10526316 0.09821429 0.11764706 0.0877193  0.09638554 0.12820513\n",
      " 0.09210526 0.0862069  0.08955224 0.14516129 0.11538462 0.15\n",
      " 0.09433962 0.0989011  0.09333333 0.09459459 0.14583333 0.09174312\n",
      " 0.13461538 0.14893617 0.13978495 0.14102564 0.09473684 0.0962963\n",
      " 0.12903226 0.09482759 0.1372549  0.09734513 0.14864865 0.09923664\n",
      " 0.09345794 0.09649123 0.14473684 0.14414414 0.14444444 0.09243697\n",
      " 0.09722222 0.14423077 0.09836066 0.09401709 0.14782609 0.14876033\n",
      " 0.1369863  0.13924051 0.09195402 0.14666667 0.14492754 0.14159292\n",
      " 0.14678899 0.14754098 0.09876543 0.1440678  0.14953271 0.08988764\n",
      " 0.14150943 0.09574468 0.14503817 0.09708738 0.13207547 0.1484375 ]\n",
      "\n",
      "\n",
      "is_large_city\n",
      "\n",
      "[ True False]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for col in train.columns:\n",
    "    print('{}\\n'.format(str(col)))\n",
    "    print(train[col].unique())\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 13034 entries, 0 to 13033\n",
      "Data columns (total 34 columns):\n",
      " #   Column                                     Non-Null Count  Dtype  \n",
      "---  ------                                     --------------  -----  \n",
      " 0   individualnumber                           13034 non-null  int64  \n",
      " 1   category_number                            13034 non-null  int64  \n",
      " 2   hakkedis_amt                               13034 non-null  float64\n",
      " 3   odul_amt                                   13034 non-null  float64\n",
      " 4   response                                   13034 non-null  int64  \n",
      " 5   total_money_spent                          13034 non-null  float64\n",
      " 6   total_discount                             13034 non-null  float64\n",
      " 7   sanal_percent                              13034 non-null  float64\n",
      " 8   shop_count                                 13034 non-null  float64\n",
      " 9   months_since_last_shopping                 13034 non-null  float64\n",
      " 10  days_shopped                               13034 non-null  float64\n",
      " 11  gender                                     13033 non-null  object \n",
      " 12  city_code                                  13034 non-null  float64\n",
      " 13  age                                        13028 non-null  float64\n",
      " 14  level1_relevant_category_volume            13034 non-null  float64\n",
      " 15  level2_relevant_category_volume            13034 non-null  float64\n",
      " 16  level3_relevant_category_volume            13034 non-null  float64\n",
      " 17  level4_relevant_category_volume            13034 non-null  float64\n",
      " 18  level1_relevant_category_quantity          13034 non-null  float64\n",
      " 19  level2_relevant_category_quantity          13034 non-null  float64\n",
      " 20  level3_relevant_category_quantity          13034 non-null  float64\n",
      " 21  level4_relevant_category_quantity          13034 non-null  float64\n",
      " 22  level1_relevant_category_volume_per_day    13034 non-null  float64\n",
      " 23  level2_relevant_category_volume_per_day    13034 non-null  float64\n",
      " 24  level3_relevant_category_volume_per_day    13034 non-null  float64\n",
      " 25  level4_relevant_category_volume_per_day    13034 non-null  float64\n",
      " 26  level1_relevant_category_quantity_per_day  13034 non-null  float64\n",
      " 27  level2_relevant_category_quantity_per_day  13034 non-null  float64\n",
      " 28  level3_relevant_category_quantity_per_day  13034 non-null  float64\n",
      " 29  level4_relevant_category_quantity_per_day  13034 non-null  float64\n",
      " 30  total_money_spent_per_day                  13034 non-null  float64\n",
      " 31  discount_per_day                           13034 non-null  float64\n",
      " 32  odul/hakkedis                              13034 non-null  float64\n",
      " 33  is_large_city                              13034 non-null  bool   \n",
      "dtypes: bool(1), float64(29), int64(3), object(1)\n",
      "memory usage: 3.3+ MB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tree\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\indexing.py:1637: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_block(indexer, value, name)\n",
      "c:\\Users\\tree\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\indexing.py:1637: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_block(indexer, value, name)\n"
     ]
    }
   ],
   "source": [
    "avg_age = round(train.age.mean())\n",
    "train.age.iloc[train.query('age.isnull()').index] = avg_age\n",
    "train.age.iloc[train.query('age<0').index] = avg_age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category_number</th>\n",
       "      <th>hakkedis_amt</th>\n",
       "      <th>odul_amt</th>\n",
       "      <th>total_money_spent</th>\n",
       "      <th>total_discount</th>\n",
       "      <th>sanal_percent</th>\n",
       "      <th>shop_count</th>\n",
       "      <th>months_since_last_shopping</th>\n",
       "      <th>days_shopped</th>\n",
       "      <th>gender</th>\n",
       "      <th>...</th>\n",
       "      <th>level2_relevant_category_volume_per_day</th>\n",
       "      <th>level3_relevant_category_volume_per_day</th>\n",
       "      <th>level4_relevant_category_volume_per_day</th>\n",
       "      <th>level1_relevant_category_quantity_per_day</th>\n",
       "      <th>level2_relevant_category_quantity_per_day</th>\n",
       "      <th>level3_relevant_category_quantity_per_day</th>\n",
       "      <th>level4_relevant_category_quantity_per_day</th>\n",
       "      <th>total_money_spent_per_day</th>\n",
       "      <th>discount_per_day</th>\n",
       "      <th>odul/hakkedis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9000</td>\n",
       "      <td>21.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7118.94741</td>\n",
       "      <td>177.489978</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>64.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>357.0</td>\n",
       "      <td>E</td>\n",
       "      <td>...</td>\n",
       "      <td>1.365154</td>\n",
       "      <td>0.675378</td>\n",
       "      <td>0.675378</td>\n",
       "      <td>0.270924</td>\n",
       "      <td>0.131653</td>\n",
       "      <td>0.100840</td>\n",
       "      <td>0.100840</td>\n",
       "      <td>19.941029</td>\n",
       "      <td>0.497171</td>\n",
       "      <td>0.095238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9000</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10192.64563</td>\n",
       "      <td>31907.260487</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>309.0</td>\n",
       "      <td>E</td>\n",
       "      <td>...</td>\n",
       "      <td>0.342718</td>\n",
       "      <td>0.342718</td>\n",
       "      <td>0.342718</td>\n",
       "      <td>0.113528</td>\n",
       "      <td>0.038835</td>\n",
       "      <td>0.038835</td>\n",
       "      <td>0.038835</td>\n",
       "      <td>32.985908</td>\n",
       "      <td>103.259743</td>\n",
       "      <td>0.058824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9030</td>\n",
       "      <td>22.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11559.66676</td>\n",
       "      <td>231.976316</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>350.0</td>\n",
       "      <td>K</td>\n",
       "      <td>...</td>\n",
       "      <td>0.396143</td>\n",
       "      <td>0.396143</td>\n",
       "      <td>0.396143</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.022857</td>\n",
       "      <td>0.022857</td>\n",
       "      <td>0.022857</td>\n",
       "      <td>33.027619</td>\n",
       "      <td>0.662789</td>\n",
       "      <td>0.090909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9001</td>\n",
       "      <td>38.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>461.77380</td>\n",
       "      <td>1.738800</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>188.0</td>\n",
       "      <td>E</td>\n",
       "      <td>...</td>\n",
       "      <td>0.202128</td>\n",
       "      <td>0.202128</td>\n",
       "      <td>0.202128</td>\n",
       "      <td>0.058511</td>\n",
       "      <td>0.010638</td>\n",
       "      <td>0.010638</td>\n",
       "      <td>0.010638</td>\n",
       "      <td>2.456244</td>\n",
       "      <td>0.009249</td>\n",
       "      <td>0.078947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9046</td>\n",
       "      <td>85.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>180.57000</td>\n",
       "      <td>19.349210</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>K</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.920957</td>\n",
       "      <td>0.205843</td>\n",
       "      <td>0.094118</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   category_number  hakkedis_amt  odul_amt  total_money_spent  total_discount  \\\n",
       "0             9000          21.0       2.0         7118.94741      177.489978   \n",
       "1             9000          17.0       1.0        10192.64563    31907.260487   \n",
       "2             9030          22.0       2.0        11559.66676      231.976316   \n",
       "3             9001          38.0       3.0          461.77380        1.738800   \n",
       "4             9046          85.0       8.0          180.57000       19.349210   \n",
       "\n",
       "   sanal_percent  shop_count  months_since_last_shopping  days_shopped gender  \\\n",
       "0       0.015625        64.0                         1.0         357.0      E   \n",
       "1       0.000000        30.0                         1.0         309.0      E   \n",
       "2       0.950000        40.0                         1.0         350.0      K   \n",
       "3       0.000000         4.0                         3.0         188.0      E   \n",
       "4       0.000000         6.0                         1.0          94.0      K   \n",
       "\n",
       "   ...  level2_relevant_category_volume_per_day  \\\n",
       "0  ...                                 1.365154   \n",
       "1  ...                                 0.342718   \n",
       "2  ...                                 0.396143   \n",
       "3  ...                                 0.202128   \n",
       "4  ...                                 0.000000   \n",
       "\n",
       "   level3_relevant_category_volume_per_day  \\\n",
       "0                                 0.675378   \n",
       "1                                 0.342718   \n",
       "2                                 0.396143   \n",
       "3                                 0.202128   \n",
       "4                                 0.000000   \n",
       "\n",
       "   level4_relevant_category_volume_per_day  \\\n",
       "0                                 0.675378   \n",
       "1                                 0.342718   \n",
       "2                                 0.396143   \n",
       "3                                 0.202128   \n",
       "4                                 0.000000   \n",
       "\n",
       "   level1_relevant_category_quantity_per_day  \\\n",
       "0                                   0.270924   \n",
       "1                                   0.113528   \n",
       "2                                   0.040000   \n",
       "3                                   0.058511   \n",
       "4                                   0.000000   \n",
       "\n",
       "   level2_relevant_category_quantity_per_day  \\\n",
       "0                                   0.131653   \n",
       "1                                   0.038835   \n",
       "2                                   0.022857   \n",
       "3                                   0.010638   \n",
       "4                                   0.000000   \n",
       "\n",
       "   level3_relevant_category_quantity_per_day  \\\n",
       "0                                   0.100840   \n",
       "1                                   0.038835   \n",
       "2                                   0.022857   \n",
       "3                                   0.010638   \n",
       "4                                   0.000000   \n",
       "\n",
       "   level4_relevant_category_quantity_per_day  total_money_spent_per_day  \\\n",
       "0                                   0.100840                  19.941029   \n",
       "1                                   0.038835                  32.985908   \n",
       "2                                   0.022857                  33.027619   \n",
       "3                                   0.010638                   2.456244   \n",
       "4                                   0.000000                   1.920957   \n",
       "\n",
       "   discount_per_day  odul/hakkedis  \n",
       "0          0.497171       0.095238  \n",
       "1        103.259743       0.058824  \n",
       "2          0.662789       0.090909  \n",
       "3          0.009249       0.078947  \n",
       "4          0.205843       0.094118  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = train.drop(['individualnumber', 'response', 'city_code', 'is_large_city'], axis=1).copy()\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1], dtype=int64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = train['response'].copy()\n",
    "y.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hakkedis_amt</th>\n",
       "      <th>odul_amt</th>\n",
       "      <th>total_money_spent</th>\n",
       "      <th>total_discount</th>\n",
       "      <th>sanal_percent</th>\n",
       "      <th>shop_count</th>\n",
       "      <th>months_since_last_shopping</th>\n",
       "      <th>days_shopped</th>\n",
       "      <th>age</th>\n",
       "      <th>level1_relevant_category_volume</th>\n",
       "      <th>...</th>\n",
       "      <th>category_number_9049</th>\n",
       "      <th>category_number_9052</th>\n",
       "      <th>category_number_9053</th>\n",
       "      <th>category_number_9054</th>\n",
       "      <th>category_number_9055</th>\n",
       "      <th>category_number_9056</th>\n",
       "      <th>category_number_9058</th>\n",
       "      <th>category_number_9059</th>\n",
       "      <th>category_number_9060</th>\n",
       "      <th>category_number_9061</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7118.94741</td>\n",
       "      <td>177.489978</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>64.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>357.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>996.749</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10192.64563</td>\n",
       "      <td>31907.260487</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>309.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>461.227</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11559.66676</td>\n",
       "      <td>231.976316</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>350.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>308.150</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>38.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>461.77380</td>\n",
       "      <td>1.738800</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>188.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>115.700</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>85.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>180.57000</td>\n",
       "      <td>19.349210</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 79 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   hakkedis_amt  odul_amt  total_money_spent  total_discount  sanal_percent  \\\n",
       "0          21.0       2.0         7118.94741      177.489978       0.015625   \n",
       "1          17.0       1.0        10192.64563    31907.260487       0.000000   \n",
       "2          22.0       2.0        11559.66676      231.976316       0.950000   \n",
       "3          38.0       3.0          461.77380        1.738800       0.000000   \n",
       "4          85.0       8.0          180.57000       19.349210       0.000000   \n",
       "\n",
       "   shop_count  months_since_last_shopping  days_shopped   age  \\\n",
       "0        64.0                         1.0         357.0  39.0   \n",
       "1        30.0                         1.0         309.0  71.0   \n",
       "2        40.0                         1.0         350.0  61.0   \n",
       "3         4.0                         3.0         188.0  38.0   \n",
       "4         6.0                         1.0          94.0  23.0   \n",
       "\n",
       "   level1_relevant_category_volume  ...  category_number_9049  \\\n",
       "0                          996.749  ...                     0   \n",
       "1                          461.227  ...                     0   \n",
       "2                          308.150  ...                     0   \n",
       "3                          115.700  ...                     0   \n",
       "4                            0.000  ...                     0   \n",
       "\n",
       "   category_number_9052  category_number_9053  category_number_9054  \\\n",
       "0                     0                     0                     0   \n",
       "1                     0                     0                     0   \n",
       "2                     0                     0                     0   \n",
       "3                     0                     0                     0   \n",
       "4                     0                     0                     0   \n",
       "\n",
       "   category_number_9055  category_number_9056  category_number_9058  \\\n",
       "0                     0                     0                     0   \n",
       "1                     0                     0                     0   \n",
       "2                     0                     0                     0   \n",
       "3                     0                     0                     0   \n",
       "4                     0                     0                     0   \n",
       "\n",
       "   category_number_9059  category_number_9060  category_number_9061  \n",
       "0                     0                     0                     0  \n",
       "1                     0                     0                     0  \n",
       "2                     0                     0                     0  \n",
       "3                     0                     0                     0  \n",
       "4                     0                     0                     0  \n",
       "\n",
       "[5 rows x 79 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_encoded = pd.get_dummies(X, columns=['gender', 'category_number'])\n",
    "X_encoded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 13034 entries, 0 to 13033\n",
      "Data columns (total 79 columns):\n",
      " #   Column                                     Non-Null Count  Dtype  \n",
      "---  ------                                     --------------  -----  \n",
      " 0   hakkedis_amt                               13034 non-null  float64\n",
      " 1   odul_amt                                   13034 non-null  float64\n",
      " 2   total_money_spent                          13034 non-null  float64\n",
      " 3   total_discount                             13034 non-null  float64\n",
      " 4   sanal_percent                              13034 non-null  float64\n",
      " 5   shop_count                                 13034 non-null  float64\n",
      " 6   months_since_last_shopping                 13034 non-null  float64\n",
      " 7   days_shopped                               13034 non-null  float64\n",
      " 8   age                                        13034 non-null  float64\n",
      " 9   level1_relevant_category_volume            13034 non-null  float64\n",
      " 10  level2_relevant_category_volume            13034 non-null  float64\n",
      " 11  level3_relevant_category_volume            13034 non-null  float64\n",
      " 12  level4_relevant_category_volume            13034 non-null  float64\n",
      " 13  level1_relevant_category_quantity          13034 non-null  float64\n",
      " 14  level2_relevant_category_quantity          13034 non-null  float64\n",
      " 15  level3_relevant_category_quantity          13034 non-null  float64\n",
      " 16  level4_relevant_category_quantity          13034 non-null  float64\n",
      " 17  level1_relevant_category_volume_per_day    13034 non-null  float64\n",
      " 18  level2_relevant_category_volume_per_day    13034 non-null  float64\n",
      " 19  level3_relevant_category_volume_per_day    13034 non-null  float64\n",
      " 20  level4_relevant_category_volume_per_day    13034 non-null  float64\n",
      " 21  level1_relevant_category_quantity_per_day  13034 non-null  float64\n",
      " 22  level2_relevant_category_quantity_per_day  13034 non-null  float64\n",
      " 23  level3_relevant_category_quantity_per_day  13034 non-null  float64\n",
      " 24  level4_relevant_category_quantity_per_day  13034 non-null  float64\n",
      " 25  total_money_spent_per_day                  13034 non-null  float64\n",
      " 26  discount_per_day                           13034 non-null  float64\n",
      " 27  odul/hakkedis                              13034 non-null  float64\n",
      " 28  gender_E                                   13034 non-null  uint8  \n",
      " 29  gender_K                                   13034 non-null  uint8  \n",
      " 30  category_number_9000                       13034 non-null  uint8  \n",
      " 31  category_number_9001                       13034 non-null  uint8  \n",
      " 32  category_number_9002                       13034 non-null  uint8  \n",
      " 33  category_number_9003                       13034 non-null  uint8  \n",
      " 34  category_number_9004                       13034 non-null  uint8  \n",
      " 35  category_number_9005                       13034 non-null  uint8  \n",
      " 36  category_number_9006                       13034 non-null  uint8  \n",
      " 37  category_number_9007                       13034 non-null  uint8  \n",
      " 38  category_number_9008                       13034 non-null  uint8  \n",
      " 39  category_number_9009                       13034 non-null  uint8  \n",
      " 40  category_number_9010                       13034 non-null  uint8  \n",
      " 41  category_number_9011                       13034 non-null  uint8  \n",
      " 42  category_number_9012                       13034 non-null  uint8  \n",
      " 43  category_number_9015                       13034 non-null  uint8  \n",
      " 44  category_number_9017                       13034 non-null  uint8  \n",
      " 45  category_number_9018                       13034 non-null  uint8  \n",
      " 46  category_number_9019                       13034 non-null  uint8  \n",
      " 47  category_number_9020                       13034 non-null  uint8  \n",
      " 48  category_number_9021                       13034 non-null  uint8  \n",
      " 49  category_number_9022                       13034 non-null  uint8  \n",
      " 50  category_number_9024                       13034 non-null  uint8  \n",
      " 51  category_number_9027                       13034 non-null  uint8  \n",
      " 52  category_number_9028                       13034 non-null  uint8  \n",
      " 53  category_number_9029                       13034 non-null  uint8  \n",
      " 54  category_number_9030                       13034 non-null  uint8  \n",
      " 55  category_number_9031                       13034 non-null  uint8  \n",
      " 56  category_number_9032                       13034 non-null  uint8  \n",
      " 57  category_number_9035                       13034 non-null  uint8  \n",
      " 58  category_number_9036                       13034 non-null  uint8  \n",
      " 59  category_number_9037                       13034 non-null  uint8  \n",
      " 60  category_number_9038                       13034 non-null  uint8  \n",
      " 61  category_number_9039                       13034 non-null  uint8  \n",
      " 62  category_number_9040                       13034 non-null  uint8  \n",
      " 63  category_number_9041                       13034 non-null  uint8  \n",
      " 64  category_number_9042                       13034 non-null  uint8  \n",
      " 65  category_number_9043                       13034 non-null  uint8  \n",
      " 66  category_number_9044                       13034 non-null  uint8  \n",
      " 67  category_number_9046                       13034 non-null  uint8  \n",
      " 68  category_number_9048                       13034 non-null  uint8  \n",
      " 69  category_number_9049                       13034 non-null  uint8  \n",
      " 70  category_number_9052                       13034 non-null  uint8  \n",
      " 71  category_number_9053                       13034 non-null  uint8  \n",
      " 72  category_number_9054                       13034 non-null  uint8  \n",
      " 73  category_number_9055                       13034 non-null  uint8  \n",
      " 74  category_number_9056                       13034 non-null  uint8  \n",
      " 75  category_number_9058                       13034 non-null  uint8  \n",
      " 76  category_number_9059                       13034 non-null  uint8  \n",
      " 77  category_number_9060                       13034 non-null  uint8  \n",
      " 78  category_number_9061                       13034 non-null  uint8  \n",
      "dtypes: float64(28), uint8(51)\n",
      "memory usage: 3.4 MB\n"
     ]
    }
   ],
   "source": [
    "X_encoded.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train ratio: 0.015447570332480818\n",
      "test ratio:0.015342129487572876\n",
      "#0/#1 is 63.84577114427861\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, stratify=y)\n",
    "print('train ratio: {}\\ntest ratio:{}'.format(sum(y_train)/len(y_train),sum(y_test)/len(y_test)))\n",
    "print('#0/#1 is {}'.format((len(y)-sum(y))/sum(y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-auc:0.82700\n",
      "[2]\tvalidation_0-auc:0.81306\n",
      "[4]\tvalidation_0-auc:0.79668\n",
      "[6]\tvalidation_0-auc:0.78057\n",
      "[8]\tvalidation_0-auc:0.82127\n",
      "[10]\tvalidation_0-auc:0.83301\n",
      "[12]\tvalidation_0-auc:0.83479\n",
      "[14]\tvalidation_0-auc:0.85216\n",
      "[16]\tvalidation_0-auc:0.84282\n",
      "[18]\tvalidation_0-auc:0.85068\n",
      "[20]\tvalidation_0-auc:0.85641\n",
      "[22]\tvalidation_0-auc:0.85111\n",
      "[24]\tvalidation_0-auc:0.85424\n",
      "[26]\tvalidation_0-auc:0.85081\n",
      "[28]\tvalidation_0-auc:0.84496\n",
      "[30]\tvalidation_0-auc:0.83864\n",
      "[32]\tvalidation_0-auc:0.83784\n",
      "[34]\tvalidation_0-auc:0.84524\n",
      "[36]\tvalidation_0-auc:0.84742\n",
      "[38]\tvalidation_0-auc:0.84016\n",
      "[40]\tvalidation_0-auc:0.83210\n",
      "[42]\tvalidation_0-auc:0.82904\n",
      "[44]\tvalidation_0-auc:0.82916\n",
      "[46]\tvalidation_0-auc:0.82581\n",
      "[48]\tvalidation_0-auc:0.83422\n",
      "[49]\tvalidation_0-auc:0.83333\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-65 {color: black;background-color: white;}#sk-container-id-65 pre{padding: 0;}#sk-container-id-65 div.sk-toggleable {background-color: white;}#sk-container-id-65 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-65 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-65 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-65 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-65 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-65 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-65 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-65 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-65 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-65 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-65 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-65 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-65 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-65 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-65 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-65 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-65 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-65 div.sk-item {position: relative;z-index: 1;}#sk-container-id-65 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-65 div.sk-item::before, #sk-container-id-65 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-65 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-65 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-65 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-65 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-65 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-65 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-65 div.sk-label-container {text-align: center;}#sk-container-id-65 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-65 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-65\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=0.2, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=&#x27;auc&#x27;, feature_types=None, gamma=0, gpu_id=-1,\n",
       "              grow_policy=&#x27;depthwise&#x27;, importance_type=None,\n",
       "              interaction_constraints=&#x27;&#x27;, learning_rate=0.13, max_bin=256,\n",
       "              max_cat_threshold=64, max_cat_to_onehot=4, max_delta_step=0,\n",
       "              max_depth=8, max_leaves=0, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints=&#x27;()&#x27;, n_estimators=50, n_jobs=0,\n",
       "              num_parallel_tree=1, predictor=&#x27;auto&#x27;, random_state=0, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-65\" type=\"checkbox\" checked><label for=\"sk-estimator-id-65\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=0.2, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=&#x27;auc&#x27;, feature_types=None, gamma=0, gpu_id=-1,\n",
       "              grow_policy=&#x27;depthwise&#x27;, importance_type=None,\n",
       "              interaction_constraints=&#x27;&#x27;, learning_rate=0.13, max_bin=256,\n",
       "              max_cat_threshold=64, max_cat_to_onehot=4, max_delta_step=0,\n",
       "              max_depth=8, max_leaves=0, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints=&#x27;()&#x27;, n_estimators=50, n_jobs=0,\n",
       "              num_parallel_tree=1, predictor=&#x27;auto&#x27;, random_state=0, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=0.2, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric='auc', feature_types=None, gamma=0, gpu_id=-1,\n",
       "              grow_policy='depthwise', importance_type=None,\n",
       "              interaction_constraints='', learning_rate=0.13, max_bin=256,\n",
       "              max_cat_threshold=64, max_cat_to_onehot=4, max_delta_step=0,\n",
       "              max_depth=8, max_leaves=0, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints='()', n_estimators=50, n_jobs=0,\n",
       "              num_parallel_tree=1, predictor='auto', random_state=0, ...)"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb0 = xgb.XGBClassifier(scale_pos_weight=63, max_depth=8,learning_rate=0.13, n_estimators=50, objective='binary:logistic',\n",
    "                         booster='gbtree', subsample=0.2, eval_metric='auc', colsample_bynode=.2)\n",
    "\n",
    "eval_set = [(X_test,y_test)]\n",
    "xgb0.fit(X_train, y_train, verbose=2, eval_set=eval_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test\n",
      "Confusion Matrix:\n",
      "[[3141   68]\n",
      " [  32   18]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.98      3209\n",
      "           1       0.21      0.36      0.26        50\n",
      "\n",
      "    accuracy                           0.97      3259\n",
      "   macro avg       0.60      0.67      0.62      3259\n",
      "weighted avg       0.98      0.97      0.97      3259\n",
      "\n",
      "0.22842639593908634\n",
      "Train\n",
      "Confusion Matrix:\n",
      "[[9454  170]\n",
      " [  33  118]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99      9624\n",
      "           1       0.41      0.78      0.54       151\n",
      "\n",
      "    accuracy                           0.98      9775\n",
      "   macro avg       0.70      0.88      0.76      9775\n",
      "weighted avg       0.99      0.98      0.98      9775\n",
      "\n",
      "0.45280122793553335\n"
     ]
    }
   ],
   "source": [
    "y_predict_test = xgb0.predict(X_test)\n",
    "y_predict_train = xgb0.predict(X_train)\n",
    "print('Test\\nConfusion Matrix:')\n",
    "print(confusion_matrix(y_test, y_predict_test))\n",
    "print(classification_report(y_test,y_predict_test))\n",
    "print(metrics.fbeta_score(y_test, y_predict_test, beta=0.5))\n",
    "print('Train\\nConfusion Matrix:')\n",
    "print(confusion_matrix(y_train, y_predict_train))\n",
    "print(classification_report(y_train,y_predict_train))\n",
    "print(metrics.fbeta_score(y_train, y_predict_train, beta=0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-auc:0.87190\n",
      "[2]\tvalidation_0-auc:0.88772\n",
      "[4]\tvalidation_0-auc:0.87957\n",
      "[6]\tvalidation_0-auc:0.88455\n",
      "[8]\tvalidation_0-auc:0.87817\n",
      "[10]\tvalidation_0-auc:0.86512\n",
      "[12]\tvalidation_0-auc:0.86309\n",
      "[14]\tvalidation_0-auc:0.86722\n",
      "[16]\tvalidation_0-auc:0.87765\n",
      "[18]\tvalidation_0-auc:0.88547\n",
      "[20]\tvalidation_0-auc:0.88622\n",
      "[22]\tvalidation_0-auc:0.89099\n",
      "[24]\tvalidation_0-auc:0.89236\n",
      "[26]\tvalidation_0-auc:0.89401\n",
      "[28]\tvalidation_0-auc:0.89829\n",
      "[30]\tvalidation_0-auc:0.89678\n",
      "[32]\tvalidation_0-auc:0.89743\n",
      "[34]\tvalidation_0-auc:0.89946\n",
      "[36]\tvalidation_0-auc:0.89892\n",
      "[38]\tvalidation_0-auc:0.90025\n",
      "[40]\tvalidation_0-auc:0.89872\n",
      "[42]\tvalidation_0-auc:0.90203\n",
      "[44]\tvalidation_0-auc:0.90039\n",
      "[46]\tvalidation_0-auc:0.89888\n",
      "[48]\tvalidation_0-auc:0.89768\n",
      "[49]\tvalidation_0-auc:0.89898\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-26 {color: black;background-color: white;}#sk-container-id-26 pre{padding: 0;}#sk-container-id-26 div.sk-toggleable {background-color: white;}#sk-container-id-26 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-26 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-26 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-26 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-26 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-26 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-26 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-26 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-26 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-26 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-26 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-26 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-26 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-26 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-26 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-26 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-26 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-26 div.sk-item {position: relative;z-index: 1;}#sk-container-id-26 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-26 div.sk-item::before, #sk-container-id-26 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-26 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-26 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-26 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-26 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-26 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-26 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-26 div.sk-label-container {text-align: center;}#sk-container-id-26 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-26 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-26\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=0.2, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=&#x27;auc&#x27;, feature_types=None, gamma=0, gpu_id=-1,\n",
       "              grow_policy=&#x27;depthwise&#x27;, importance_type=None,\n",
       "              interaction_constraints=&#x27;&#x27;, learning_rate=0.1, max_bin=256,\n",
       "              max_cat_threshold=64, max_cat_to_onehot=4, max_delta_step=0,\n",
       "              max_depth=5, max_leaves=0, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints=&#x27;()&#x27;, n_estimators=50, n_jobs=0,\n",
       "              num_parallel_tree=1, predictor=&#x27;auto&#x27;, random_state=0, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-26\" type=\"checkbox\" checked><label for=\"sk-estimator-id-26\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=0.2, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=&#x27;auc&#x27;, feature_types=None, gamma=0, gpu_id=-1,\n",
       "              grow_policy=&#x27;depthwise&#x27;, importance_type=None,\n",
       "              interaction_constraints=&#x27;&#x27;, learning_rate=0.1, max_bin=256,\n",
       "              max_cat_threshold=64, max_cat_to_onehot=4, max_delta_step=0,\n",
       "              max_depth=5, max_leaves=0, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints=&#x27;()&#x27;, n_estimators=50, n_jobs=0,\n",
       "              num_parallel_tree=1, predictor=&#x27;auto&#x27;, random_state=0, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=0.2, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric='auc', feature_types=None, gamma=0, gpu_id=-1,\n",
       "              grow_policy='depthwise', importance_type=None,\n",
       "              interaction_constraints='', learning_rate=0.1, max_bin=256,\n",
       "              max_cat_threshold=64, max_cat_to_onehot=4, max_delta_step=0,\n",
       "              max_depth=5, max_leaves=0, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints='()', n_estimators=50, n_jobs=0,\n",
       "              num_parallel_tree=1, predictor='auto', random_state=0, ...)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#MODEL 1\n",
    "model1 = xgb.XGBClassifier(scale_pos_weight=64, max_depth=5,learning_rate=0.1, n_estimators=50, objective='binary:logistic',\n",
    "                         booster='gbtree', subsample=0.5, eval_metric='auc', colsample_bynode=.2)\n",
    "\n",
    "eval_set = [(X_test,y_test)]\n",
    "model1.fit(X_train, y_train, verbose=2, eval_set=eval_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-auc:0.84039\n",
      "[2]\tvalidation_0-auc:0.86620\n",
      "[4]\tvalidation_0-auc:0.87479\n",
      "[6]\tvalidation_0-auc:0.86580\n",
      "[8]\tvalidation_0-auc:0.85529\n",
      "[10]\tvalidation_0-auc:0.85919\n",
      "[12]\tvalidation_0-auc:0.88963\n",
      "[14]\tvalidation_0-auc:0.88545\n",
      "[16]\tvalidation_0-auc:0.88386\n",
      "[18]\tvalidation_0-auc:0.88485\n",
      "[20]\tvalidation_0-auc:0.88719\n",
      "[22]\tvalidation_0-auc:0.89581\n",
      "[24]\tvalidation_0-auc:0.89564\n",
      "[26]\tvalidation_0-auc:0.89264\n",
      "[28]\tvalidation_0-auc:0.89351\n",
      "[30]\tvalidation_0-auc:0.89126\n",
      "[32]\tvalidation_0-auc:0.89508\n",
      "[34]\tvalidation_0-auc:0.89260\n",
      "[36]\tvalidation_0-auc:0.89415\n",
      "[38]\tvalidation_0-auc:0.90023\n",
      "[40]\tvalidation_0-auc:0.89860\n",
      "[42]\tvalidation_0-auc:0.89773\n",
      "[44]\tvalidation_0-auc:0.89744\n",
      "[46]\tvalidation_0-auc:0.89192\n",
      "[48]\tvalidation_0-auc:0.88945\n",
      "[49]\tvalidation_0-auc:0.88934\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-27 {color: black;background-color: white;}#sk-container-id-27 pre{padding: 0;}#sk-container-id-27 div.sk-toggleable {background-color: white;}#sk-container-id-27 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-27 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-27 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-27 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-27 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-27 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-27 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-27 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-27 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-27 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-27 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-27 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-27 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-27 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-27 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-27 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-27 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-27 div.sk-item {position: relative;z-index: 1;}#sk-container-id-27 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-27 div.sk-item::before, #sk-container-id-27 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-27 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-27 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-27 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-27 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-27 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-27 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-27 div.sk-label-container {text-align: center;}#sk-container-id-27 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-27 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-27\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=0.2, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=&#x27;auc&#x27;, feature_types=None, gamma=0, gpu_id=-1,\n",
       "              grow_policy=&#x27;depthwise&#x27;, importance_type=None,\n",
       "              interaction_constraints=&#x27;&#x27;, learning_rate=0.1, max_bin=256,\n",
       "              max_cat_threshold=64, max_cat_to_onehot=4, max_delta_step=0,\n",
       "              max_depth=6, max_leaves=0, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints=&#x27;()&#x27;, n_estimators=50, n_jobs=0,\n",
       "              num_parallel_tree=1, predictor=&#x27;auto&#x27;, random_state=0, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-27\" type=\"checkbox\" checked><label for=\"sk-estimator-id-27\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=0.2, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=&#x27;auc&#x27;, feature_types=None, gamma=0, gpu_id=-1,\n",
       "              grow_policy=&#x27;depthwise&#x27;, importance_type=None,\n",
       "              interaction_constraints=&#x27;&#x27;, learning_rate=0.1, max_bin=256,\n",
       "              max_cat_threshold=64, max_cat_to_onehot=4, max_delta_step=0,\n",
       "              max_depth=6, max_leaves=0, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints=&#x27;()&#x27;, n_estimators=50, n_jobs=0,\n",
       "              num_parallel_tree=1, predictor=&#x27;auto&#x27;, random_state=0, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=0.2, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric='auc', feature_types=None, gamma=0, gpu_id=-1,\n",
       "              grow_policy='depthwise', importance_type=None,\n",
       "              interaction_constraints='', learning_rate=0.1, max_bin=256,\n",
       "              max_cat_threshold=64, max_cat_to_onehot=4, max_delta_step=0,\n",
       "              max_depth=6, max_leaves=0, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints='()', n_estimators=50, n_jobs=0,\n",
       "              num_parallel_tree=1, predictor='auto', random_state=0, ...)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#MODEL 2\n",
    "model2 = xgb.XGBClassifier(scale_pos_weight=63, max_depth=6,learning_rate=0.1, n_estimators=50, objective='binary:logistic',\n",
    "                         booster='gbtree', subsample=0.2, eval_metric='auc', colsample_bynode=.2)\n",
    "\n",
    "eval_set = [(X_test,y_test)]\n",
    "model2.fit(X_train, y_train, verbose=2, eval_set=eval_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-auc:0.83385\n",
      "[2]\tvalidation_0-auc:0.86157\n",
      "[4]\tvalidation_0-auc:0.87022\n",
      "[6]\tvalidation_0-auc:0.85066\n",
      "[8]\tvalidation_0-auc:0.85541\n",
      "[10]\tvalidation_0-auc:0.87001\n",
      "[12]\tvalidation_0-auc:0.84900\n",
      "[14]\tvalidation_0-auc:0.86250\n",
      "[16]\tvalidation_0-auc:0.86155\n",
      "[18]\tvalidation_0-auc:0.87964\n",
      "[20]\tvalidation_0-auc:0.87912\n",
      "[22]\tvalidation_0-auc:0.88351\n",
      "[24]\tvalidation_0-auc:0.88441\n",
      "[26]\tvalidation_0-auc:0.88727\n",
      "[28]\tvalidation_0-auc:0.88629\n",
      "[30]\tvalidation_0-auc:0.88639\n",
      "[32]\tvalidation_0-auc:0.88830\n",
      "[34]\tvalidation_0-auc:0.89018\n",
      "[36]\tvalidation_0-auc:0.88781\n",
      "[38]\tvalidation_0-auc:0.88992\n",
      "[40]\tvalidation_0-auc:0.89121\n",
      "[42]\tvalidation_0-auc:0.88845\n",
      "[44]\tvalidation_0-auc:0.88710\n",
      "[46]\tvalidation_0-auc:0.88207\n",
      "[48]\tvalidation_0-auc:0.88609\n",
      "[49]\tvalidation_0-auc:0.88613\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-28 {color: black;background-color: white;}#sk-container-id-28 pre{padding: 0;}#sk-container-id-28 div.sk-toggleable {background-color: white;}#sk-container-id-28 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-28 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-28 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-28 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-28 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-28 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-28 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-28 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-28 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-28 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-28 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-28 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-28 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-28 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-28 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-28 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-28 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-28 div.sk-item {position: relative;z-index: 1;}#sk-container-id-28 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-28 div.sk-item::before, #sk-container-id-28 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-28 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-28 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-28 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-28 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-28 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-28 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-28 div.sk-label-container {text-align: center;}#sk-container-id-28 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-28 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-28\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=0.25, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=&#x27;auc&#x27;, feature_types=None, gamma=0, gpu_id=-1,\n",
       "              grow_policy=&#x27;depthwise&#x27;, importance_type=None,\n",
       "              interaction_constraints=&#x27;&#x27;, learning_rate=0.1, max_bin=256,\n",
       "              max_cat_threshold=64, max_cat_to_onehot=4, max_delta_step=0,\n",
       "              max_depth=7, max_leaves=0, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints=&#x27;()&#x27;, n_estimators=50, n_jobs=0,\n",
       "              num_parallel_tree=1, predictor=&#x27;auto&#x27;, random_state=0, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-28\" type=\"checkbox\" checked><label for=\"sk-estimator-id-28\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=0.25, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=&#x27;auc&#x27;, feature_types=None, gamma=0, gpu_id=-1,\n",
       "              grow_policy=&#x27;depthwise&#x27;, importance_type=None,\n",
       "              interaction_constraints=&#x27;&#x27;, learning_rate=0.1, max_bin=256,\n",
       "              max_cat_threshold=64, max_cat_to_onehot=4, max_delta_step=0,\n",
       "              max_depth=7, max_leaves=0, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints=&#x27;()&#x27;, n_estimators=50, n_jobs=0,\n",
       "              num_parallel_tree=1, predictor=&#x27;auto&#x27;, random_state=0, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=0.25, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric='auc', feature_types=None, gamma=0, gpu_id=-1,\n",
       "              grow_policy='depthwise', importance_type=None,\n",
       "              interaction_constraints='', learning_rate=0.1, max_bin=256,\n",
       "              max_cat_threshold=64, max_cat_to_onehot=4, max_delta_step=0,\n",
       "              max_depth=7, max_leaves=0, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints='()', n_estimators=50, n_jobs=0,\n",
       "              num_parallel_tree=1, predictor='auto', random_state=0, ...)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#MODEL 3\n",
    "model3 = xgb.XGBClassifier(scale_pos_weight=63, max_depth=7,learning_rate=0.1, n_estimators=50, objective='binary:logistic',\n",
    "                         booster='gbtree', subsample=0.2, eval_metric='auc', colsample_bynode=.25)\n",
    "\n",
    "eval_set = [(X_test,y_test)]\n",
    "model3.fit(X_train, y_train, verbose=2, eval_set=eval_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MODEL 4\n",
    "model4 = xgb.XGBClassifier(scale_pos_weight=63, max_depth=8,learning_rate=0.08, n_estimators=50, objective='binary:logistic',\n",
    "                         booster='gbtree', subsample=0.2, eval_metric='auc', colsample_bynode=.2)\n",
    "\n",
    "eval_set = [(X_test,y_test)]\n",
    "model4.fit(X_train, y_train, verbose=2, eval_set=eval_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MODEL 5\n",
    "model5 = xgb.XGBClassifier(scale_pos_weight=63, max_depth=8,learning_rate=0.13, n_estimators=50, objective='binary:logistic',\n",
    "                         booster='gbtree', subsample=0.2, eval_metric='auc', colsample_bynode=.2)\n",
    "\n",
    "eval_set = [(X_test,y_test)]\n",
    "model5.fit(X_train, y_train, verbose=2, eval_set=eval_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PREDICTION AND SUBMISSION OF REAL TEST DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tree\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\indexing.py:1637: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_block(indexer, value, name)\n",
      "c:\\Users\\tree\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\indexing.py:1637: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_block(indexer, value, name)\n"
     ]
    }
   ],
   "source": [
    "avg_age = round(test.age.mean())\n",
    "test.age.iloc[test.query('age.isnull()').index] = avg_age\n",
    "test.age.iloc[test.query('age<0').index] = avg_age\n",
    "X_TEST = test.drop(['individualnumber', 'city_code', 'is_large_city'], axis=1).copy()\n",
    "X_TEST_encoded = pd.get_dummies(X_TEST, columns=['gender', 'category_number'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict_xgb0 = xgb0.predict(X_TEST_encoded)\n",
    "submission = pd.DataFrame()\n",
    "submission['individualnumber'] = test['individualnumber']\n",
    "submission['response'] = y_predict_xgb0\n",
    "submission.to_csv('./submissions/submission4.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PARAMETER TUNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skopt import BayesSearchCV\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tree\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\indexing.py:1637: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_block(indexer, value, name)\n",
      "c:\\Users\\tree\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\indexing.py:1637: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_block(indexer, value, name)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('../organized_data/train_cleaned_v1.csv')\n",
    "test = pd.read_csv('../organized_data/test_organized.csv')\n",
    "avg_age = round(train.age.mean())\n",
    "train.age.iloc[train.query('age.isnull()').index] = avg_age\n",
    "train.age.iloc[train.query('age<0').index] = avg_age\n",
    "X = train.drop(['individualnumber', 'response', 'city_code', 'is_large_city'], axis=1).copy()\n",
    "y = train['response'].copy()\n",
    "X_encoded = pd.get_dummies(X, columns=['gender', 'category_number'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train ratio: 0.015447570332480818\n",
      "test ratio:0.015342129487572876\n",
      "#0/#1 is 63.84577114427861\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, stratify=y)\n",
    "print('train ratio: {}\\ntest ratio:{}'.format(sum(y_train)/len(y_train),sum(y_test)/len(y_test)))\n",
    "print('#0/#1 is {}'.format((len(y)-sum(y))/sum(y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[CV 1/3] END colsample_bynode=0.4, colsample_bytree=0.4, gamma=0.1, learning_rate=0.175, max_depth=9, n_estimators=80, subsample=0.175;, score=(train=0.725, test=0.200) total time=   1.1s\n",
      "[CV 2/3] END colsample_bynode=0.4, colsample_bytree=0.4, gamma=0.1, learning_rate=0.175, max_depth=9, n_estimators=80, subsample=0.175;, score=(train=0.803, test=0.232) total time=   1.1s\n",
      "[CV 3/3] END colsample_bynode=0.4, colsample_bytree=0.4, gamma=0.1, learning_rate=0.175, max_depth=9, n_estimators=80, subsample=0.175;, score=(train=0.800, test=0.194) total time=   1.2s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[CV 1/3] END colsample_bynode=0.1, colsample_bytree=0.2, gamma=25.6, learning_rate=0.175, max_depth=7, n_estimators=60, subsample=0.225;, score=(train=0.183, test=0.145) total time=   0.3s\n",
      "[CV 2/3] END colsample_bynode=0.1, colsample_bytree=0.2, gamma=25.6, learning_rate=0.175, max_depth=7, n_estimators=60, subsample=0.225;, score=(train=0.194, test=0.160) total time=   0.4s\n",
      "[CV 3/3] END colsample_bynode=0.1, colsample_bytree=0.2, gamma=25.6, learning_rate=0.175, max_depth=7, n_estimators=60, subsample=0.225;, score=(train=0.184, test=0.170) total time=   0.4s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[CV 1/3] END colsample_bynode=0.8, colsample_bytree=0.4, gamma=1.6, learning_rate=0.125, max_depth=8, n_estimators=60, subsample=0.2;, score=(train=0.692, test=0.211) total time=   0.7s\n",
      "[CV 2/3] END colsample_bynode=0.8, colsample_bytree=0.4, gamma=1.6, learning_rate=0.125, max_depth=8, n_estimators=60, subsample=0.2;, score=(train=0.639, test=0.184) total time=   0.7s\n",
      "[CV 3/3] END colsample_bynode=0.8, colsample_bytree=0.4, gamma=1.6, learning_rate=0.125, max_depth=8, n_estimators=60, subsample=0.2;, score=(train=0.639, test=0.289) total time=   0.7s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[CV 1/3] END colsample_bynode=0.4, colsample_bytree=0.4, gamma=0.8, learning_rate=0.1, max_depth=5, n_estimators=80, subsample=0.2;, score=(train=0.492, test=0.210) total time=   0.7s\n",
      "[CV 2/3] END colsample_bynode=0.4, colsample_bytree=0.4, gamma=0.8, learning_rate=0.1, max_depth=5, n_estimators=80, subsample=0.2;, score=(train=0.551, test=0.308) total time=   0.6s\n",
      "[CV 3/3] END colsample_bynode=0.4, colsample_bytree=0.4, gamma=0.8, learning_rate=0.1, max_depth=5, n_estimators=80, subsample=0.2;, score=(train=0.517, test=0.284) total time=   0.6s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[CV 1/3] END colsample_bynode=0.2, colsample_bytree=0.8, gamma=0.8, learning_rate=0.2, max_depth=6, n_estimators=100, subsample=0.2;, score=(train=0.738, test=0.230) total time=   0.9s\n",
      "[CV 2/3] END colsample_bynode=0.2, colsample_bytree=0.8, gamma=0.8, learning_rate=0.2, max_depth=6, n_estimators=100, subsample=0.2;, score=(train=0.777, test=0.211) total time=   0.7s\n",
      "[CV 3/3] END colsample_bynode=0.2, colsample_bytree=0.8, gamma=0.8, learning_rate=0.2, max_depth=6, n_estimators=100, subsample=0.2;, score=(train=0.756, test=0.200) total time=   0.7s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[CV 1/3] END colsample_bynode=0.2, colsample_bytree=0.8, gamma=0.8, learning_rate=0.075, max_depth=10, n_estimators=50, subsample=0.225;, score=(train=0.593, test=0.176) total time=   0.4s\n",
      "[CV 2/3] END colsample_bynode=0.2, colsample_bytree=0.8, gamma=0.8, learning_rate=0.075, max_depth=10, n_estimators=50, subsample=0.225;, score=(train=0.539, test=0.275) total time=   0.4s\n",
      "[CV 3/3] END colsample_bynode=0.2, colsample_bytree=0.8, gamma=0.8, learning_rate=0.075, max_depth=10, n_estimators=50, subsample=0.225;, score=(train=0.562, test=0.271) total time=   0.4s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[CV 1/3] END colsample_bynode=0.1, colsample_bytree=0.4, gamma=3.2, learning_rate=0.15, max_depth=6, n_estimators=60, subsample=0.225;, score=(train=0.362, test=0.205) total time=   0.4s\n",
      "[CV 2/3] END colsample_bynode=0.1, colsample_bytree=0.4, gamma=3.2, learning_rate=0.15, max_depth=6, n_estimators=60, subsample=0.225;, score=(train=0.375, test=0.204) total time=   0.4s\n",
      "[CV 3/3] END colsample_bynode=0.1, colsample_bytree=0.4, gamma=3.2, learning_rate=0.15, max_depth=6, n_estimators=60, subsample=0.225;, score=(train=0.299, test=0.218) total time=   0.3s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[CV 1/3] END colsample_bynode=0.4, colsample_bytree=0.4, gamma=0.8, learning_rate=0.075, max_depth=9, n_estimators=90, subsample=0.225;, score=(train=0.707, test=0.191) total time=   0.7s\n",
      "[CV 2/3] END colsample_bynode=0.4, colsample_bytree=0.4, gamma=0.8, learning_rate=0.075, max_depth=9, n_estimators=90, subsample=0.225;, score=(train=0.726, test=0.283) total time=   0.6s\n",
      "[CV 3/3] END colsample_bynode=0.4, colsample_bytree=0.4, gamma=0.8, learning_rate=0.075, max_depth=9, n_estimators=90, subsample=0.225;, score=(train=0.704, test=0.257) total time=   0.6s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[CV 1/3] END colsample_bynode=0.1, colsample_bytree=0.2, gamma=0.8, learning_rate=0.1, max_depth=7, n_estimators=60, subsample=0.25;, score=(train=0.182, test=0.138) total time=   0.3s\n",
      "[CV 2/3] END colsample_bynode=0.1, colsample_bytree=0.2, gamma=0.8, learning_rate=0.1, max_depth=7, n_estimators=60, subsample=0.25;, score=(train=0.182, test=0.160) total time=   0.3s\n",
      "[CV 3/3] END colsample_bynode=0.1, colsample_bytree=0.2, gamma=0.8, learning_rate=0.1, max_depth=7, n_estimators=60, subsample=0.25;, score=(train=0.171, test=0.145) total time=   0.3s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[CV 1/3] END colsample_bynode=0.4, colsample_bytree=0.4, gamma=25.6, learning_rate=0.075, max_depth=6, n_estimators=70, subsample=0.175;, score=(train=0.425, test=0.199) total time=   0.4s\n",
      "[CV 2/3] END colsample_bynode=0.4, colsample_bytree=0.4, gamma=25.6, learning_rate=0.075, max_depth=6, n_estimators=70, subsample=0.175;, score=(train=0.369, test=0.283) total time=   0.5s\n",
      "[CV 3/3] END colsample_bynode=0.4, colsample_bytree=0.4, gamma=25.6, learning_rate=0.075, max_depth=6, n_estimators=70, subsample=0.175;, score=(train=0.383, test=0.287) total time=   0.4s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[CV 1/3] END colsample_bynode=0.4, colsample_bytree=0.4, gamma=0.8, learning_rate=0.075, max_depth=5, n_estimators=90, subsample=0.225;, score=(train=0.469, test=0.212) total time=   0.6s\n",
      "[CV 2/3] END colsample_bynode=0.4, colsample_bytree=0.4, gamma=0.8, learning_rate=0.075, max_depth=5, n_estimators=90, subsample=0.225;, score=(train=0.481, test=0.248) total time=   0.6s\n",
      "[CV 3/3] END colsample_bynode=0.4, colsample_bytree=0.4, gamma=0.8, learning_rate=0.075, max_depth=5, n_estimators=90, subsample=0.225;, score=(train=0.443, test=0.284) total time=   0.5s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[CV 1/3] END colsample_bynode=0.4, colsample_bytree=0.8, gamma=0.4, learning_rate=0.1, max_depth=5, n_estimators=70, subsample=0.2;, score=(train=0.549, test=0.195) total time=   0.5s\n",
      "[CV 2/3] END colsample_bynode=0.4, colsample_bytree=0.8, gamma=0.4, learning_rate=0.1, max_depth=5, n_estimators=70, subsample=0.2;, score=(train=0.495, test=0.275) total time=   0.5s\n",
      "[CV 3/3] END colsample_bynode=0.4, colsample_bytree=0.8, gamma=0.4, learning_rate=0.1, max_depth=5, n_estimators=70, subsample=0.2;, score=(train=0.435, test=0.257) total time=   0.5s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[CV 1/3] END colsample_bynode=0.4, colsample_bytree=0.2, gamma=12.8, learning_rate=0.1, max_depth=5, n_estimators=70, subsample=0.175;, score=(train=0.351, test=0.201) total time=   0.4s\n",
      "[CV 2/3] END colsample_bynode=0.4, colsample_bytree=0.2, gamma=12.8, learning_rate=0.1, max_depth=5, n_estimators=70, subsample=0.175;, score=(train=0.409, test=0.269) total time=   0.4s\n",
      "[CV 3/3] END colsample_bynode=0.4, colsample_bytree=0.2, gamma=12.8, learning_rate=0.1, max_depth=5, n_estimators=70, subsample=0.175;, score=(train=0.362, test=0.276) total time=   0.4s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[CV 1/3] END colsample_bynode=0.4, colsample_bytree=0.4, gamma=12.8, learning_rate=0.05, max_depth=5, n_estimators=80, subsample=0.15;, score=(train=0.343, test=0.219) total time=   0.4s\n",
      "[CV 2/3] END colsample_bynode=0.4, colsample_bytree=0.4, gamma=12.8, learning_rate=0.05, max_depth=5, n_estimators=80, subsample=0.15;, score=(train=0.343, test=0.284) total time=   0.5s\n",
      "[CV 3/3] END colsample_bynode=0.4, colsample_bytree=0.4, gamma=12.8, learning_rate=0.05, max_depth=5, n_estimators=80, subsample=0.15;, score=(train=0.332, test=0.306) total time=   0.5s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[CV 1/3] END colsample_bynode=0.4, colsample_bytree=0.4, gamma=12.8, learning_rate=0.15, max_depth=5, n_estimators=60, subsample=0.175;, score=(train=0.516, test=0.198) total time=   0.5s\n",
      "[CV 2/3] END colsample_bynode=0.4, colsample_bytree=0.4, gamma=12.8, learning_rate=0.15, max_depth=5, n_estimators=60, subsample=0.175;, score=(train=0.474, test=0.280) total time=   0.4s\n",
      "[CV 3/3] END colsample_bynode=0.4, colsample_bytree=0.4, gamma=12.8, learning_rate=0.15, max_depth=5, n_estimators=60, subsample=0.175;, score=(train=0.476, test=0.293) total time=   0.4s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[CV 1/3] END colsample_bynode=0.2, colsample_bytree=0.4, gamma=0.2, learning_rate=0.125, max_depth=9, n_estimators=50, subsample=0.175;, score=(train=0.524, test=0.176) total time=   0.4s\n",
      "[CV 2/3] END colsample_bynode=0.2, colsample_bytree=0.4, gamma=0.2, learning_rate=0.125, max_depth=9, n_estimators=50, subsample=0.175;, score=(train=0.514, test=0.218) total time=   0.6s\n",
      "[CV 3/3] END colsample_bynode=0.2, colsample_bytree=0.4, gamma=0.2, learning_rate=0.125, max_depth=9, n_estimators=50, subsample=0.175;, score=(train=0.521, test=0.277) total time=   0.4s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[CV 1/3] END colsample_bynode=0.2, colsample_bytree=0.2, gamma=0.1, learning_rate=0.075, max_depth=7, n_estimators=80, subsample=0.2;, score=(train=0.367, test=0.213) total time=   0.5s\n",
      "[CV 2/3] END colsample_bynode=0.2, colsample_bytree=0.2, gamma=0.1, learning_rate=0.075, max_depth=7, n_estimators=80, subsample=0.2;, score=(train=0.394, test=0.283) total time=   0.5s\n",
      "[CV 3/3] END colsample_bynode=0.2, colsample_bytree=0.2, gamma=0.1, learning_rate=0.075, max_depth=7, n_estimators=80, subsample=0.2;, score=(train=0.330, test=0.248) total time=   0.5s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[CV 1/3] END colsample_bynode=0.4, colsample_bytree=0.8, gamma=0.8, learning_rate=0.175, max_depth=6, n_estimators=60, subsample=0.25;, score=(train=0.704, test=0.254) total time=   0.5s\n",
      "[CV 2/3] END colsample_bynode=0.4, colsample_bytree=0.8, gamma=0.8, learning_rate=0.175, max_depth=6, n_estimators=60, subsample=0.25;, score=(train=0.757, test=0.204) total time=   0.5s\n",
      "[CV 3/3] END colsample_bynode=0.4, colsample_bytree=0.8, gamma=0.8, learning_rate=0.175, max_depth=6, n_estimators=60, subsample=0.25;, score=(train=0.627, test=0.266) total time=   0.5s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[CV 1/3] END colsample_bynode=0.4, colsample_bytree=0.4, gamma=0.4, learning_rate=0.1, max_depth=8, n_estimators=60, subsample=0.25;, score=(train=0.646, test=0.203) total time=   0.5s\n",
      "[CV 2/3] END colsample_bynode=0.4, colsample_bytree=0.4, gamma=0.4, learning_rate=0.1, max_depth=8, n_estimators=60, subsample=0.25;, score=(train=0.672, test=0.250) total time=   0.6s\n",
      "[CV 3/3] END colsample_bynode=0.4, colsample_bytree=0.4, gamma=0.4, learning_rate=0.1, max_depth=8, n_estimators=60, subsample=0.25;, score=(train=0.590, test=0.323) total time=   0.6s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[CV 1/3] END colsample_bynode=0.4, colsample_bytree=0.4, gamma=12.8, learning_rate=0.075, max_depth=7, n_estimators=90, subsample=0.175;, score=(train=0.532, test=0.201) total time=   0.6s\n",
      "[CV 2/3] END colsample_bynode=0.4, colsample_bytree=0.4, gamma=12.8, learning_rate=0.075, max_depth=7, n_estimators=90, subsample=0.175;, score=(train=0.560, test=0.375) total time=   0.6s\n",
      "[CV 3/3] END colsample_bynode=0.4, colsample_bytree=0.4, gamma=12.8, learning_rate=0.075, max_depth=7, n_estimators=90, subsample=0.175;, score=(train=0.507, test=0.270) total time=   0.6s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[CV 1/3] END colsample_bynode=0.4, colsample_bytree=0.2, gamma=12.8, learning_rate=0.075, max_depth=7, n_estimators=50, subsample=0.225;, score=(train=0.374, test=0.184) total time=   0.3s\n",
      "[CV 2/3] END colsample_bynode=0.4, colsample_bytree=0.2, gamma=12.8, learning_rate=0.075, max_depth=7, n_estimators=50, subsample=0.225;, score=(train=0.388, test=0.267) total time=   0.3s\n",
      "[CV 3/3] END colsample_bynode=0.4, colsample_bytree=0.2, gamma=12.8, learning_rate=0.075, max_depth=7, n_estimators=50, subsample=0.225;, score=(train=0.383, test=0.317) total time=   0.3s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[CV 1/3] END colsample_bynode=0.4, colsample_bytree=0.4, gamma=12.8, learning_rate=0.15, max_depth=7, n_estimators=100, subsample=0.175;, score=(train=0.605, test=0.211) total time=   0.6s\n",
      "[CV 2/3] END colsample_bynode=0.4, colsample_bytree=0.4, gamma=12.8, learning_rate=0.15, max_depth=7, n_estimators=100, subsample=0.175;, score=(train=0.660, test=0.227) total time=   0.6s\n",
      "[CV 3/3] END colsample_bynode=0.4, colsample_bytree=0.4, gamma=12.8, learning_rate=0.15, max_depth=7, n_estimators=100, subsample=0.175;, score=(train=0.619, test=0.245) total time=   0.7s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[CV 1/3] END colsample_bynode=0.4, colsample_bytree=0.4, gamma=12.8, learning_rate=0.075, max_depth=8, n_estimators=90, subsample=0.175;, score=(train=0.570, test=0.184) total time=   0.8s\n",
      "[CV 2/3] END colsample_bynode=0.4, colsample_bytree=0.4, gamma=12.8, learning_rate=0.075, max_depth=8, n_estimators=90, subsample=0.175;, score=(train=0.573, test=0.318) total time=   0.7s\n",
      "[CV 3/3] END colsample_bynode=0.4, colsample_bytree=0.4, gamma=12.8, learning_rate=0.075, max_depth=8, n_estimators=90, subsample=0.175;, score=(train=0.556, test=0.293) total time=   0.7s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[CV 1/3] END colsample_bynode=0.4, colsample_bytree=0.4, gamma=12.8, learning_rate=0.075, max_depth=10, n_estimators=90, subsample=0.225;, score=(train=0.619, test=0.203) total time=   0.7s\n",
      "[CV 2/3] END colsample_bynode=0.4, colsample_bytree=0.4, gamma=12.8, learning_rate=0.075, max_depth=10, n_estimators=90, subsample=0.225;, score=(train=0.651, test=0.262) total time=   0.7s\n",
      "[CV 3/3] END colsample_bynode=0.4, colsample_bytree=0.4, gamma=12.8, learning_rate=0.075, max_depth=10, n_estimators=90, subsample=0.225;, score=(train=0.667, test=0.278) total time=   0.8s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[CV 1/3] END colsample_bynode=0.4, colsample_bytree=0.2, gamma=12.8, learning_rate=0.075, max_depth=8, n_estimators=50, subsample=0.25;, score=(train=0.411, test=0.155) total time=   0.4s\n",
      "[CV 2/3] END colsample_bynode=0.4, colsample_bytree=0.2, gamma=12.8, learning_rate=0.075, max_depth=8, n_estimators=50, subsample=0.25;, score=(train=0.444, test=0.287) total time=   0.3s\n",
      "[CV 3/3] END colsample_bynode=0.4, colsample_bytree=0.2, gamma=12.8, learning_rate=0.075, max_depth=8, n_estimators=50, subsample=0.25;, score=(train=0.446, test=0.333) total time=   0.3s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[CV 1/3] END colsample_bynode=0.4, colsample_bytree=0.2, gamma=0.2, learning_rate=0.075, max_depth=7, n_estimators=60, subsample=0.175;, score=(train=0.415, test=0.221) total time=   0.4s\n",
      "[CV 2/3] END colsample_bynode=0.4, colsample_bytree=0.2, gamma=0.2, learning_rate=0.075, max_depth=7, n_estimators=60, subsample=0.175;, score=(train=0.430, test=0.238) total time=   0.5s\n",
      "[CV 3/3] END colsample_bynode=0.4, colsample_bytree=0.2, gamma=0.2, learning_rate=0.075, max_depth=7, n_estimators=60, subsample=0.175;, score=(train=0.365, test=0.293) total time=   0.6s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[CV 1/3] END colsample_bynode=0.4, colsample_bytree=0.2, gamma=12.8, learning_rate=0.125, max_depth=6, n_estimators=60, subsample=0.25;, score=(train=0.446, test=0.195) total time=   0.5s\n",
      "[CV 2/3] END colsample_bynode=0.4, colsample_bytree=0.2, gamma=12.8, learning_rate=0.125, max_depth=6, n_estimators=60, subsample=0.25;, score=(train=0.479, test=0.254) total time=   0.6s\n",
      "[CV 3/3] END colsample_bynode=0.4, colsample_bytree=0.2, gamma=12.8, learning_rate=0.125, max_depth=6, n_estimators=60, subsample=0.25;, score=(train=0.452, test=0.232) total time=   0.6s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[CV 1/3] END colsample_bynode=0.8, colsample_bytree=0.8, gamma=12.8, learning_rate=0.075, max_depth=6, n_estimators=80, subsample=0.175;, score=(train=0.482, test=0.175) total time=   1.2s\n",
      "[CV 2/3] END colsample_bynode=0.8, colsample_bytree=0.8, gamma=12.8, learning_rate=0.075, max_depth=6, n_estimators=80, subsample=0.175;, score=(train=0.550, test=0.291) total time=   1.4s\n",
      "[CV 3/3] END colsample_bynode=0.8, colsample_bytree=0.8, gamma=12.8, learning_rate=0.075, max_depth=6, n_estimators=80, subsample=0.175;, score=(train=0.490, test=0.314) total time=   1.3s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[CV 1/3] END colsample_bynode=0.8, colsample_bytree=0.4, gamma=3.2, learning_rate=0.05, max_depth=6, n_estimators=50, subsample=0.25;, score=(train=0.375, test=0.238) total time=   0.6s\n",
      "[CV 2/3] END colsample_bynode=0.8, colsample_bytree=0.4, gamma=3.2, learning_rate=0.05, max_depth=6, n_estimators=50, subsample=0.25;, score=(train=0.341, test=0.257) total time=   0.7s\n",
      "[CV 3/3] END colsample_bynode=0.8, colsample_bytree=0.4, gamma=3.2, learning_rate=0.05, max_depth=6, n_estimators=50, subsample=0.25;, score=(train=0.311, test=0.267) total time=   0.6s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[CV 1/3] END colsample_bynode=0.8, colsample_bytree=0.8, gamma=25.6, learning_rate=0.15, max_depth=5, n_estimators=80, subsample=0.15;, score=(train=0.474, test=0.243) total time=   0.7s\n",
      "[CV 2/3] END colsample_bynode=0.8, colsample_bytree=0.8, gamma=25.6, learning_rate=0.15, max_depth=5, n_estimators=80, subsample=0.15;, score=(train=0.439, test=0.249) total time=   0.7s\n",
      "[CV 3/3] END colsample_bynode=0.8, colsample_bytree=0.8, gamma=25.6, learning_rate=0.15, max_depth=5, n_estimators=80, subsample=0.15;, score=(train=0.486, test=0.225) total time=   0.7s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[CV 1/3] END colsample_bynode=0.4, colsample_bytree=0.4, gamma=12.8, learning_rate=0.2, max_depth=8, n_estimators=80, subsample=0.15;, score=(train=0.551, test=0.158) total time=   0.5s\n",
      "[CV 2/3] END colsample_bynode=0.4, colsample_bytree=0.4, gamma=12.8, learning_rate=0.2, max_depth=8, n_estimators=80, subsample=0.15;, score=(train=0.538, test=0.237) total time=   0.5s\n",
      "[CV 3/3] END colsample_bynode=0.4, colsample_bytree=0.4, gamma=12.8, learning_rate=0.2, max_depth=8, n_estimators=80, subsample=0.15;, score=(train=0.557, test=0.286) total time=   0.5s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[CV 1/3] END colsample_bynode=0.4, colsample_bytree=0.2, gamma=0.2, learning_rate=0.05, max_depth=7, n_estimators=90, subsample=0.15;, score=(train=0.404, test=0.174) total time=   0.6s\n",
      "[CV 2/3] END colsample_bynode=0.4, colsample_bytree=0.2, gamma=0.2, learning_rate=0.05, max_depth=7, n_estimators=90, subsample=0.15;, score=(train=0.434, test=0.288) total time=   0.8s\n",
      "[CV 3/3] END colsample_bynode=0.4, colsample_bytree=0.2, gamma=0.2, learning_rate=0.05, max_depth=7, n_estimators=90, subsample=0.15;, score=(train=0.399, test=0.336) total time=   0.9s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[CV 1/3] END colsample_bynode=0.4, colsample_bytree=0.4, gamma=0.0, learning_rate=0.05, max_depth=5, n_estimators=50, subsample=0.15;, score=(train=0.294, test=0.208) total time=   0.4s\n",
      "[CV 2/3] END colsample_bynode=0.4, colsample_bytree=0.4, gamma=0.0, learning_rate=0.05, max_depth=5, n_estimators=50, subsample=0.15;, score=(train=0.293, test=0.269) total time=   0.4s\n",
      "[CV 3/3] END colsample_bynode=0.4, colsample_bytree=0.4, gamma=0.0, learning_rate=0.05, max_depth=5, n_estimators=50, subsample=0.15;, score=(train=0.273, test=0.282) total time=   0.5s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[CV 1/3] END colsample_bynode=0.8, colsample_bytree=0.2, gamma=0.2, learning_rate=0.075, max_depth=6, n_estimators=90, subsample=0.225;, score=(train=0.601, test=0.174) total time=   0.6s\n",
      "[CV 2/3] END colsample_bynode=0.8, colsample_bytree=0.2, gamma=0.2, learning_rate=0.075, max_depth=6, n_estimators=90, subsample=0.225;, score=(train=0.560, test=0.308) total time=   0.6s\n",
      "[CV 3/3] END colsample_bynode=0.8, colsample_bytree=0.2, gamma=0.2, learning_rate=0.075, max_depth=6, n_estimators=90, subsample=0.225;, score=(train=0.509, test=0.312) total time=   0.6s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[CV 1/3] END colsample_bynode=0.8, colsample_bytree=0.2, gamma=12.8, learning_rate=0.075, max_depth=9, n_estimators=90, subsample=0.175;, score=(train=0.607, test=0.194) total time=   0.6s\n",
      "[CV 2/3] END colsample_bynode=0.8, colsample_bytree=0.2, gamma=12.8, learning_rate=0.075, max_depth=9, n_estimators=90, subsample=0.175;, score=(train=0.607, test=0.278) total time=   0.6s\n",
      "[CV 3/3] END colsample_bynode=0.8, colsample_bytree=0.2, gamma=12.8, learning_rate=0.075, max_depth=9, n_estimators=90, subsample=0.175;, score=(train=0.581, test=0.293) total time=   0.7s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[CV 1/3] END colsample_bynode=0.8, colsample_bytree=0.8, gamma=12.8, learning_rate=0.075, max_depth=10, n_estimators=90, subsample=0.175;, score=(train=0.602, test=0.194) total time=   1.0s\n",
      "[CV 2/3] END colsample_bynode=0.8, colsample_bytree=0.8, gamma=12.8, learning_rate=0.075, max_depth=10, n_estimators=90, subsample=0.175;, score=(train=0.649, test=0.286) total time=   1.1s\n",
      "[CV 3/3] END colsample_bynode=0.8, colsample_bytree=0.8, gamma=12.8, learning_rate=0.075, max_depth=10, n_estimators=90, subsample=0.175;, score=(train=0.644, test=0.283) total time=   1.1s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[CV 1/3] END colsample_bynode=0.8, colsample_bytree=0.2, gamma=3.2, learning_rate=0.075, max_depth=7, n_estimators=90, subsample=0.225;, score=(train=0.595, test=0.178) total time=   0.6s\n",
      "[CV 2/3] END colsample_bynode=0.8, colsample_bytree=0.2, gamma=3.2, learning_rate=0.075, max_depth=7, n_estimators=90, subsample=0.225;, score=(train=0.619, test=0.241) total time=   0.6s\n",
      "[CV 3/3] END colsample_bynode=0.8, colsample_bytree=0.2, gamma=3.2, learning_rate=0.075, max_depth=7, n_estimators=90, subsample=0.225;, score=(train=0.570, test=0.311) total time=   0.7s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[CV 1/3] END colsample_bynode=0.4, colsample_bytree=0.8, gamma=12.8, learning_rate=0.05, max_depth=6, n_estimators=60, subsample=0.25;, score=(train=0.379, test=0.205) total time=   0.6s\n",
      "[CV 2/3] END colsample_bynode=0.4, colsample_bytree=0.8, gamma=12.8, learning_rate=0.05, max_depth=6, n_estimators=60, subsample=0.25;, score=(train=0.369, test=0.265) total time=   0.5s\n",
      "[CV 3/3] END colsample_bynode=0.4, colsample_bytree=0.8, gamma=12.8, learning_rate=0.05, max_depth=6, n_estimators=60, subsample=0.25;, score=(train=0.330, test=0.286) total time=   0.5s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[CV 1/3] END colsample_bynode=0.8, colsample_bytree=0.4, gamma=12.8, learning_rate=0.05, max_depth=8, n_estimators=90, subsample=0.175;, score=(train=0.500, test=0.185) total time=   0.8s\n",
      "[CV 2/3] END colsample_bynode=0.8, colsample_bytree=0.4, gamma=12.8, learning_rate=0.05, max_depth=8, n_estimators=90, subsample=0.175;, score=(train=0.520, test=0.315) total time=   0.8s\n",
      "[CV 3/3] END colsample_bynode=0.8, colsample_bytree=0.4, gamma=12.8, learning_rate=0.05, max_depth=8, n_estimators=90, subsample=0.175;, score=(train=0.518, test=0.328) total time=   0.9s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[CV 1/3] END colsample_bynode=0.2, colsample_bytree=0.4, gamma=51.2, learning_rate=0.05, max_depth=8, n_estimators=90, subsample=0.175;, score=(train=0.292, test=0.211) total time=   0.6s\n",
      "[CV 2/3] END colsample_bynode=0.2, colsample_bytree=0.4, gamma=51.2, learning_rate=0.05, max_depth=8, n_estimators=90, subsample=0.175;, score=(train=0.307, test=0.220) total time=   0.6s\n",
      "[CV 3/3] END colsample_bynode=0.2, colsample_bytree=0.4, gamma=51.2, learning_rate=0.05, max_depth=8, n_estimators=90, subsample=0.175;, score=(train=0.309, test=0.289) total time=   0.6s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[CV 1/3] END colsample_bynode=0.8, colsample_bytree=0.4, gamma=0.8, learning_rate=0.1, max_depth=8, n_estimators=90, subsample=0.175;, score=(train=0.693, test=0.191) total time=   0.7s\n",
      "[CV 2/3] END colsample_bynode=0.8, colsample_bytree=0.4, gamma=0.8, learning_rate=0.1, max_depth=8, n_estimators=90, subsample=0.175;, score=(train=0.743, test=0.259) total time=   0.7s\n",
      "[CV 3/3] END colsample_bynode=0.8, colsample_bytree=0.4, gamma=0.8, learning_rate=0.1, max_depth=8, n_estimators=90, subsample=0.175;, score=(train=0.706, test=0.299) total time=   0.7s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[CV 1/3] END colsample_bynode=0.8, colsample_bytree=0.8, gamma=12.8, learning_rate=0.2, max_depth=8, n_estimators=90, subsample=0.175;, score=(train=0.662, test=0.202) total time=   2.1s\n",
      "[CV 2/3] END colsample_bynode=0.8, colsample_bytree=0.8, gamma=12.8, learning_rate=0.2, max_depth=8, n_estimators=90, subsample=0.175;, score=(train=0.681, test=0.179) total time=   1.9s\n",
      "[CV 3/3] END colsample_bynode=0.8, colsample_bytree=0.8, gamma=12.8, learning_rate=0.2, max_depth=8, n_estimators=90, subsample=0.175;, score=(train=0.642, test=0.248) total time=   1.4s\n",
      "Test\n",
      "\n",
      "[[3114   95]\n",
      " [  34   16]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98      3209\n",
      "           1       0.14      0.32      0.20        50\n",
      "\n",
      "    accuracy                           0.96      3259\n",
      "   macro avg       0.57      0.65      0.59      3259\n",
      "weighted avg       0.98      0.96      0.97      3259\n",
      "\n",
      "0.16194331983805668\n",
      "Train\n",
      "\n",
      "[[9381  243]\n",
      " [  40  111]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.99      9624\n",
      "           1       0.31      0.74      0.44       151\n",
      "\n",
      "    accuracy                           0.97      9775\n",
      "   macro avg       0.65      0.85      0.71      9775\n",
      "weighted avg       0.99      0.97      0.98      9775\n",
      "\n",
      "0.3541799617102744\n"
     ]
    }
   ],
   "source": [
    "#TUNING ROUND 1\n",
    "param_grid = {'gamma':[0, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4],\n",
    "              'learning_rate':[0.075, 0.1, 0.125],\n",
    "              'max_depth':[9, 10, 11, 12],\n",
    "              'n_estimators':[90, 95, 100, 105, 110, 120, 150, 180],\n",
    "              'subsample':[0.175, 0.2, 0.225],\n",
    "              'colsample_bynode':[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],\n",
    "              'colsample_bytree':[0.6, 0.7, 0.8, 0.9],\n",
    "              'reg_alpha':[0, 0.1, 0.2, 0.4, 0.8],\n",
    "              'reg_lambda':[0, 0.1, 0.2, 0.4, 0.8]}\n",
    "\n",
    "gcvj = np.cumsum([len(x) for x in param_grid.values()])[-1]\n",
    "bcvj = int(gcvj)\n",
    "\n",
    "xgbc = xgb.XGBClassifier(objective='binary:logistic',\n",
    "                          booster='gbtree',\n",
    "                          scale_pos_weight=63,\n",
    "                          eval_metric='auc')\n",
    "\n",
    "clf = BayesSearchCV(estimator=xgbc, search_spaces=param_grid, n_iter=bcvj, scoring='f1', cv=3, return_train_score=True, verbose=3)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "df = pd.DataFrame(clf.cv_results_)\n",
    "\n",
    "train_pred = clf.predict(X_train)\n",
    "test_pred = clf.predict(X_test)\n",
    "\n",
    "print('Test\\n')\n",
    "print(confusion_matrix(y_test, test_pred))\n",
    "print(classification_report(y_test,test_pred))\n",
    "print(metrics.fbeta_score(y_test, test_pred, beta=0.5))\n",
    "print('Train\\n')\n",
    "print(confusion_matrix(y_train, train_pred))\n",
    "print(classification_report(y_train,train_pred))\n",
    "print(metrics.fbeta_score(y_train, train_pred, beta=0.5))\n",
    "\n",
    "bp = clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('colsample_bynode', 0.4),\n",
       "             ('colsample_bytree', 0.4),\n",
       "             ('gamma', 12.8),\n",
       "             ('learning_rate', 0.075),\n",
       "             ('max_depth', 7),\n",
       "             ('n_estimators', 90),\n",
       "             ('subsample', 0.175)])"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_df = df.sort_values(by='rank_test_score')\n",
    "sorted_df.to_csv('stats_round1.csv',index=False)\n",
    "bp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[CV 1/3] END colsample_bynode=0.7, colsample_bytree=0.4, gamma=12.8, learning_rate=0.075, max_depth=6, n_estimators=70, reg_alpha=0.0, reg_lambda=0.1, subsample=0.2;, score=(train=0.505, test=0.199) total time=   0.9s\n",
      "[CV 2/3] END colsample_bynode=0.7, colsample_bytree=0.4, gamma=12.8, learning_rate=0.075, max_depth=6, n_estimators=70, reg_alpha=0.0, reg_lambda=0.1, subsample=0.2;, score=(train=0.478, test=0.279) total time=   0.7s\n",
      "[CV 3/3] END colsample_bynode=0.7, colsample_bytree=0.4, gamma=12.8, learning_rate=0.075, max_depth=6, n_estimators=70, reg_alpha=0.0, reg_lambda=0.1, subsample=0.2;, score=(train=0.414, test=0.309) total time=   0.7s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[CV 1/3] END colsample_bynode=0.7, colsample_bytree=0.3, gamma=25.6, learning_rate=0.1, max_depth=6, n_estimators=70, reg_alpha=0.0, reg_lambda=0.2, subsample=0.175;, score=(train=0.475, test=0.209) total time=   0.7s\n",
      "[CV 2/3] END colsample_bynode=0.7, colsample_bytree=0.3, gamma=25.6, learning_rate=0.1, max_depth=6, n_estimators=70, reg_alpha=0.0, reg_lambda=0.2, subsample=0.175;, score=(train=0.445, test=0.239) total time=   0.7s\n",
      "[CV 3/3] END colsample_bynode=0.7, colsample_bytree=0.3, gamma=25.6, learning_rate=0.1, max_depth=6, n_estimators=70, reg_alpha=0.0, reg_lambda=0.2, subsample=0.175;, score=(train=0.426, test=0.298) total time=   0.6s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[CV 1/3] END colsample_bynode=0.4, colsample_bytree=0.3, gamma=25.6, learning_rate=0.075, max_depth=6, n_estimators=80, reg_alpha=0.4, reg_lambda=0.0, subsample=0.175;, score=(train=0.417, test=0.189) total time=   0.6s\n",
      "[CV 2/3] END colsample_bynode=0.4, colsample_bytree=0.3, gamma=25.6, learning_rate=0.075, max_depth=6, n_estimators=80, reg_alpha=0.4, reg_lambda=0.0, subsample=0.175;, score=(train=0.444, test=0.266) total time=   0.6s\n",
      "[CV 3/3] END colsample_bynode=0.4, colsample_bytree=0.3, gamma=25.6, learning_rate=0.075, max_depth=6, n_estimators=80, reg_alpha=0.4, reg_lambda=0.0, subsample=0.175;, score=(train=0.440, test=0.258) total time=   0.6s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[CV 1/3] END colsample_bynode=0.7, colsample_bytree=0.3, gamma=12.8, learning_rate=0.05, max_depth=5, n_estimators=90, reg_alpha=0.4, reg_lambda=0.4, subsample=0.2;, score=(train=0.335, test=0.176) total time=   1.3s\n",
      "[CV 2/3] END colsample_bynode=0.7, colsample_bytree=0.3, gamma=12.8, learning_rate=0.05, max_depth=5, n_estimators=90, reg_alpha=0.4, reg_lambda=0.4, subsample=0.2;, score=(train=0.369, test=0.261) total time=   1.1s\n",
      "[CV 3/3] END colsample_bynode=0.7, colsample_bytree=0.3, gamma=12.8, learning_rate=0.05, max_depth=5, n_estimators=90, reg_alpha=0.4, reg_lambda=0.4, subsample=0.2;, score=(train=0.338, test=0.295) total time=   1.3s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[CV 1/3] END colsample_bynode=0.7, colsample_bytree=0.3, gamma=25.6, learning_rate=0.05, max_depth=6, n_estimators=90, reg_alpha=0.2, reg_lambda=0.1, subsample=0.225;, score=(train=0.407, test=0.203) total time=   1.9s\n",
      "[CV 2/3] END colsample_bynode=0.7, colsample_bytree=0.3, gamma=25.6, learning_rate=0.05, max_depth=6, n_estimators=90, reg_alpha=0.2, reg_lambda=0.1, subsample=0.225;, score=(train=0.432, test=0.294) total time=   3.1s\n",
      "[CV 3/3] END colsample_bynode=0.7, colsample_bytree=0.3, gamma=25.6, learning_rate=0.05, max_depth=6, n_estimators=90, reg_alpha=0.2, reg_lambda=0.1, subsample=0.225;, score=(train=0.364, test=0.333) total time=   1.4s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[CV 1/3] END colsample_bynode=0.8, colsample_bytree=0.4, gamma=51.2, learning_rate=0.075, max_depth=7, n_estimators=70, reg_alpha=0.8, reg_lambda=0.4, subsample=0.175;, score=(train=0.331, test=0.218) total time=   1.2s\n",
      "[CV 2/3] END colsample_bynode=0.8, colsample_bytree=0.4, gamma=51.2, learning_rate=0.075, max_depth=7, n_estimators=70, reg_alpha=0.8, reg_lambda=0.4, subsample=0.175;, score=(train=0.342, test=0.271) total time=   1.4s\n",
      "[CV 3/3] END colsample_bynode=0.8, colsample_bytree=0.4, gamma=51.2, learning_rate=0.075, max_depth=7, n_estimators=70, reg_alpha=0.8, reg_lambda=0.4, subsample=0.175;, score=(train=0.340, test=0.300) total time=   1.2s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[CV 1/3] END colsample_bynode=0.6, colsample_bytree=0.3, gamma=12.8, learning_rate=0.05, max_depth=7, n_estimators=90, reg_alpha=0.8, reg_lambda=0.4, subsample=0.225;, score=(train=0.435, test=0.177) total time=   1.0s\n",
      "[CV 2/3] END colsample_bynode=0.6, colsample_bytree=0.3, gamma=12.8, learning_rate=0.05, max_depth=7, n_estimators=90, reg_alpha=0.8, reg_lambda=0.4, subsample=0.225;, score=(train=0.474, test=0.319) total time=   1.1s\n",
      "[CV 3/3] END colsample_bynode=0.6, colsample_bytree=0.3, gamma=12.8, learning_rate=0.05, max_depth=7, n_estimators=90, reg_alpha=0.8, reg_lambda=0.4, subsample=0.225;, score=(train=0.428, test=0.265) total time=   1.1s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[CV 1/3] END colsample_bynode=0.8, colsample_bytree=0.3, gamma=25.6, learning_rate=0.1, max_depth=6, n_estimators=100, reg_alpha=0.1, reg_lambda=0.4, subsample=0.175;, score=(train=0.514, test=0.221) total time=   0.8s\n",
      "[CV 2/3] END colsample_bynode=0.8, colsample_bytree=0.3, gamma=25.6, learning_rate=0.1, max_depth=6, n_estimators=100, reg_alpha=0.1, reg_lambda=0.4, subsample=0.175;, score=(train=0.528, test=0.268) total time=   0.7s\n",
      "[CV 3/3] END colsample_bynode=0.8, colsample_bytree=0.3, gamma=25.6, learning_rate=0.1, max_depth=6, n_estimators=100, reg_alpha=0.1, reg_lambda=0.4, subsample=0.175;, score=(train=0.554, test=0.306) total time=   0.7s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[CV 1/3] END colsample_bynode=0.7, colsample_bytree=0.4, gamma=6.4, learning_rate=0.075, max_depth=5, n_estimators=80, reg_alpha=0.2, reg_lambda=0.1, subsample=0.2;, score=(train=0.436, test=0.200) total time=   0.6s\n",
      "[CV 2/3] END colsample_bynode=0.7, colsample_bytree=0.4, gamma=6.4, learning_rate=0.075, max_depth=5, n_estimators=80, reg_alpha=0.2, reg_lambda=0.1, subsample=0.2;, score=(train=0.486, test=0.235) total time=   0.6s\n",
      "[CV 3/3] END colsample_bynode=0.7, colsample_bytree=0.4, gamma=6.4, learning_rate=0.075, max_depth=5, n_estimators=80, reg_alpha=0.2, reg_lambda=0.1, subsample=0.2;, score=(train=0.431, test=0.282) total time=   0.6s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[CV 1/3] END colsample_bynode=0.6, colsample_bytree=0.2, gamma=12.8, learning_rate=0.1, max_depth=6, n_estimators=80, reg_alpha=0.1, reg_lambda=0.2, subsample=0.2;, score=(train=0.555, test=0.201) total time=   0.5s\n",
      "[CV 2/3] END colsample_bynode=0.6, colsample_bytree=0.2, gamma=12.8, learning_rate=0.1, max_depth=6, n_estimators=80, reg_alpha=0.1, reg_lambda=0.2, subsample=0.2;, score=(train=0.674, test=0.230) total time=   0.5s\n",
      "[CV 3/3] END colsample_bynode=0.6, colsample_bytree=0.2, gamma=12.8, learning_rate=0.1, max_depth=6, n_estimators=80, reg_alpha=0.1, reg_lambda=0.2, subsample=0.2;, score=(train=0.545, test=0.286) total time=   0.5s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[CV 1/3] END colsample_bynode=0.7, colsample_bytree=0.2, gamma=6.4, learning_rate=0.075, max_depth=6, n_estimators=70, reg_alpha=0.2, reg_lambda=0.1, subsample=0.225;, score=(train=0.480, test=0.205) total time=   0.5s\n",
      "[CV 2/3] END colsample_bynode=0.7, colsample_bytree=0.2, gamma=6.4, learning_rate=0.075, max_depth=6, n_estimators=70, reg_alpha=0.2, reg_lambda=0.1, subsample=0.225;, score=(train=0.438, test=0.215) total time=   0.5s\n",
      "[CV 3/3] END colsample_bynode=0.7, colsample_bytree=0.2, gamma=6.4, learning_rate=0.075, max_depth=6, n_estimators=70, reg_alpha=0.2, reg_lambda=0.1, subsample=0.225;, score=(train=0.409, test=0.316) total time=   0.5s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[CV 1/3] END colsample_bynode=0.7, colsample_bytree=0.4, gamma=25.6, learning_rate=0.05, max_depth=7, n_estimators=70, reg_alpha=0.2, reg_lambda=0.1, subsample=0.175;, score=(train=0.430, test=0.192) total time=   0.6s\n",
      "[CV 2/3] END colsample_bynode=0.7, colsample_bytree=0.4, gamma=25.6, learning_rate=0.05, max_depth=7, n_estimators=70, reg_alpha=0.2, reg_lambda=0.1, subsample=0.175;, score=(train=0.401, test=0.318) total time=   0.6s\n",
      "[CV 3/3] END colsample_bynode=0.7, colsample_bytree=0.4, gamma=25.6, learning_rate=0.05, max_depth=7, n_estimators=70, reg_alpha=0.2, reg_lambda=0.1, subsample=0.175;, score=(train=0.351, test=0.319) total time=   0.8s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[CV 1/3] END colsample_bynode=0.7, colsample_bytree=0.2, gamma=25.6, learning_rate=0.05, max_depth=7, n_estimators=80, reg_alpha=0.2, reg_lambda=0.1, subsample=0.2;, score=(train=0.408, test=0.198) total time=   0.5s\n",
      "[CV 2/3] END colsample_bynode=0.7, colsample_bytree=0.2, gamma=25.6, learning_rate=0.05, max_depth=7, n_estimators=80, reg_alpha=0.2, reg_lambda=0.1, subsample=0.2;, score=(train=0.407, test=0.271) total time=   0.6s\n",
      "[CV 3/3] END colsample_bynode=0.7, colsample_bytree=0.2, gamma=25.6, learning_rate=0.05, max_depth=7, n_estimators=80, reg_alpha=0.2, reg_lambda=0.1, subsample=0.2;, score=(train=0.396, test=0.274) total time=   0.6s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[CV 1/3] END colsample_bynode=0.7, colsample_bytree=0.4, gamma=6.4, learning_rate=0.075, max_depth=7, n_estimators=90, reg_alpha=0.2, reg_lambda=0.1, subsample=0.225;, score=(train=0.653, test=0.226) total time=   0.8s\n",
      "[CV 2/3] END colsample_bynode=0.7, colsample_bytree=0.4, gamma=6.4, learning_rate=0.075, max_depth=7, n_estimators=90, reg_alpha=0.2, reg_lambda=0.1, subsample=0.225;, score=(train=0.646, test=0.204) total time=   0.9s\n",
      "[CV 3/3] END colsample_bynode=0.7, colsample_bytree=0.4, gamma=6.4, learning_rate=0.075, max_depth=7, n_estimators=90, reg_alpha=0.2, reg_lambda=0.1, subsample=0.225;, score=(train=0.672, test=0.294) total time=   1.0s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[CV 1/3] END colsample_bynode=0.5, colsample_bytree=0.3, gamma=25.6, learning_rate=0.05, max_depth=6, n_estimators=90, reg_alpha=0.2, reg_lambda=0.1, subsample=0.175;, score=(train=0.371, test=0.187) total time=   0.6s\n",
      "[CV 2/3] END colsample_bynode=0.5, colsample_bytree=0.3, gamma=25.6, learning_rate=0.05, max_depth=6, n_estimators=90, reg_alpha=0.2, reg_lambda=0.1, subsample=0.175;, score=(train=0.376, test=0.311) total time=   0.6s\n",
      "[CV 3/3] END colsample_bynode=0.5, colsample_bytree=0.3, gamma=25.6, learning_rate=0.05, max_depth=6, n_estimators=90, reg_alpha=0.2, reg_lambda=0.1, subsample=0.175;, score=(train=0.354, test=0.294) total time=   0.7s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[CV 1/3] END colsample_bynode=0.8, colsample_bytree=0.4, gamma=25.6, learning_rate=0.05, max_depth=6, n_estimators=70, reg_alpha=0.2, reg_lambda=0.1, subsample=0.225;, score=(train=0.365, test=0.202) total time=   0.8s\n",
      "[CV 2/3] END colsample_bynode=0.8, colsample_bytree=0.4, gamma=25.6, learning_rate=0.05, max_depth=6, n_estimators=70, reg_alpha=0.2, reg_lambda=0.1, subsample=0.225;, score=(train=0.362, test=0.256) total time=   0.7s\n",
      "[CV 3/3] END colsample_bynode=0.8, colsample_bytree=0.4, gamma=25.6, learning_rate=0.05, max_depth=6, n_estimators=70, reg_alpha=0.2, reg_lambda=0.1, subsample=0.225;, score=(train=0.325, test=0.279) total time=   0.6s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[CV 1/3] END colsample_bynode=0.7, colsample_bytree=0.3, gamma=25.6, learning_rate=0.05, max_depth=6, n_estimators=90, reg_alpha=0.2, reg_lambda=0.4, subsample=0.225;, score=(train=0.407, test=0.193) total time=   0.6s\n",
      "[CV 2/3] END colsample_bynode=0.7, colsample_bytree=0.3, gamma=25.6, learning_rate=0.05, max_depth=6, n_estimators=90, reg_alpha=0.2, reg_lambda=0.4, subsample=0.225;, score=(train=0.384, test=0.274) total time=   0.7s\n",
      "[CV 3/3] END colsample_bynode=0.7, colsample_bytree=0.3, gamma=25.6, learning_rate=0.05, max_depth=6, n_estimators=90, reg_alpha=0.2, reg_lambda=0.4, subsample=0.225;, score=(train=0.374, test=0.320) total time=   0.6s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[CV 1/3] END colsample_bynode=0.7, colsample_bytree=0.3, gamma=25.6, learning_rate=0.05, max_depth=6, n_estimators=90, reg_alpha=0.2, reg_lambda=0.2, subsample=0.175;, score=(train=0.383, test=0.203) total time=   0.6s\n",
      "[CV 2/3] END colsample_bynode=0.7, colsample_bytree=0.3, gamma=25.6, learning_rate=0.05, max_depth=6, n_estimators=90, reg_alpha=0.2, reg_lambda=0.2, subsample=0.175;, score=(train=0.357, test=0.294) total time=   0.6s\n",
      "[CV 3/3] END colsample_bynode=0.7, colsample_bytree=0.3, gamma=25.6, learning_rate=0.05, max_depth=6, n_estimators=90, reg_alpha=0.2, reg_lambda=0.2, subsample=0.175;, score=(train=0.381, test=0.304) total time=   0.6s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[CV 1/3] END colsample_bynode=0.7, colsample_bytree=0.4, gamma=25.6, learning_rate=0.075, max_depth=5, n_estimators=70, reg_alpha=0.2, reg_lambda=0.8, subsample=0.175;, score=(train=0.384, test=0.228) total time=   0.5s\n",
      "[CV 2/3] END colsample_bynode=0.7, colsample_bytree=0.4, gamma=25.6, learning_rate=0.075, max_depth=5, n_estimators=70, reg_alpha=0.2, reg_lambda=0.8, subsample=0.175;, score=(train=0.360, test=0.263) total time=   0.5s\n",
      "[CV 3/3] END colsample_bynode=0.7, colsample_bytree=0.4, gamma=25.6, learning_rate=0.075, max_depth=5, n_estimators=70, reg_alpha=0.2, reg_lambda=0.8, subsample=0.175;, score=(train=0.336, test=0.272) total time=   0.5s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[CV 1/3] END colsample_bynode=0.7, colsample_bytree=0.4, gamma=25.6, learning_rate=0.05, max_depth=6, n_estimators=100, reg_alpha=0.2, reg_lambda=0.2, subsample=0.225;, score=(train=0.447, test=0.216) total time=   0.8s\n",
      "[CV 2/3] END colsample_bynode=0.7, colsample_bytree=0.4, gamma=25.6, learning_rate=0.05, max_depth=6, n_estimators=100, reg_alpha=0.2, reg_lambda=0.2, subsample=0.225;, score=(train=0.468, test=0.307) total time=   0.8s\n",
      "[CV 3/3] END colsample_bynode=0.7, colsample_bytree=0.4, gamma=25.6, learning_rate=0.05, max_depth=6, n_estimators=100, reg_alpha=0.2, reg_lambda=0.2, subsample=0.225;, score=(train=0.422, test=0.286) total time=   0.8s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[CV 1/3] END colsample_bynode=0.7, colsample_bytree=0.4, gamma=25.6, learning_rate=0.05, max_depth=8, n_estimators=90, reg_alpha=0.2, reg_lambda=0.8, subsample=0.2;, score=(train=0.419, test=0.184) total time=   0.8s\n",
      "[CV 2/3] END colsample_bynode=0.7, colsample_bytree=0.4, gamma=25.6, learning_rate=0.05, max_depth=8, n_estimators=90, reg_alpha=0.2, reg_lambda=0.8, subsample=0.2;, score=(train=0.472, test=0.331) total time=   0.8s\n",
      "[CV 3/3] END colsample_bynode=0.7, colsample_bytree=0.4, gamma=25.6, learning_rate=0.05, max_depth=8, n_estimators=90, reg_alpha=0.2, reg_lambda=0.8, subsample=0.2;, score=(train=0.425, test=0.325) total time=   0.8s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[CV 1/3] END colsample_bynode=0.7, colsample_bytree=0.4, gamma=25.6, learning_rate=0.05, max_depth=5, n_estimators=90, reg_alpha=0.2, reg_lambda=0.0, subsample=0.175;, score=(train=0.392, test=0.216) total time=   0.7s\n",
      "[CV 2/3] END colsample_bynode=0.7, colsample_bytree=0.4, gamma=25.6, learning_rate=0.05, max_depth=5, n_estimators=90, reg_alpha=0.2, reg_lambda=0.0, subsample=0.175;, score=(train=0.362, test=0.303) total time=   0.7s\n",
      "[CV 3/3] END colsample_bynode=0.7, colsample_bytree=0.4, gamma=25.6, learning_rate=0.05, max_depth=5, n_estimators=90, reg_alpha=0.2, reg_lambda=0.0, subsample=0.175;, score=(train=0.344, test=0.328) total time=   0.7s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[CV 1/3] END colsample_bynode=0.7, colsample_bytree=0.4, gamma=6.4, learning_rate=0.05, max_depth=5, n_estimators=80, reg_alpha=0.2, reg_lambda=0.0, subsample=0.175;, score=(train=0.365, test=0.178) total time=   0.6s\n",
      "[CV 2/3] END colsample_bynode=0.7, colsample_bytree=0.4, gamma=6.4, learning_rate=0.05, max_depth=5, n_estimators=80, reg_alpha=0.2, reg_lambda=0.0, subsample=0.175;, score=(train=0.369, test=0.301) total time=   0.6s\n",
      "[CV 3/3] END colsample_bynode=0.7, colsample_bytree=0.4, gamma=6.4, learning_rate=0.05, max_depth=5, n_estimators=80, reg_alpha=0.2, reg_lambda=0.0, subsample=0.175;, score=(train=0.335, test=0.307) total time=   0.6s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[CV 1/3] END colsample_bynode=0.7, colsample_bytree=0.4, gamma=12.8, learning_rate=0.05, max_depth=5, n_estimators=90, reg_alpha=0.2, reg_lambda=0.0, subsample=0.175;, score=(train=0.385, test=0.188) total time=   0.6s\n",
      "[CV 2/3] END colsample_bynode=0.7, colsample_bytree=0.4, gamma=12.8, learning_rate=0.05, max_depth=5, n_estimators=90, reg_alpha=0.2, reg_lambda=0.0, subsample=0.175;, score=(train=0.381, test=0.307) total time=   0.7s\n",
      "[CV 3/3] END colsample_bynode=0.7, colsample_bytree=0.4, gamma=12.8, learning_rate=0.05, max_depth=5, n_estimators=90, reg_alpha=0.2, reg_lambda=0.0, subsample=0.175;, score=(train=0.343, test=0.316) total time=   0.7s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[CV 1/3] END colsample_bynode=0.7, colsample_bytree=0.4, gamma=25.6, learning_rate=0.05, max_depth=5, n_estimators=90, reg_alpha=0.2, reg_lambda=0.4, subsample=0.2;, score=(train=0.354, test=0.207) total time=   0.9s\n",
      "[CV 2/3] END colsample_bynode=0.7, colsample_bytree=0.4, gamma=25.6, learning_rate=0.05, max_depth=5, n_estimators=90, reg_alpha=0.2, reg_lambda=0.4, subsample=0.2;, score=(train=0.379, test=0.287) total time=   0.7s\n",
      "[CV 3/3] END colsample_bynode=0.7, colsample_bytree=0.4, gamma=25.6, learning_rate=0.05, max_depth=5, n_estimators=90, reg_alpha=0.2, reg_lambda=0.4, subsample=0.2;, score=(train=0.327, test=0.271) total time=   0.7s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[CV 1/3] END colsample_bynode=0.7, colsample_bytree=0.4, gamma=51.2, learning_rate=0.05, max_depth=5, n_estimators=90, reg_alpha=0.2, reg_lambda=0.8, subsample=0.2;, score=(train=0.315, test=0.211) total time=   0.7s\n",
      "[CV 2/3] END colsample_bynode=0.7, colsample_bytree=0.4, gamma=51.2, learning_rate=0.05, max_depth=5, n_estimators=90, reg_alpha=0.2, reg_lambda=0.8, subsample=0.2;, score=(train=0.305, test=0.248) total time=   0.7s\n",
      "[CV 3/3] END colsample_bynode=0.7, colsample_bytree=0.4, gamma=51.2, learning_rate=0.05, max_depth=5, n_estimators=90, reg_alpha=0.2, reg_lambda=0.8, subsample=0.2;, score=(train=0.304, test=0.272) total time=   0.7s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[CV 1/3] END colsample_bynode=0.7, colsample_bytree=0.4, gamma=12.8, learning_rate=0.05, max_depth=7, n_estimators=70, reg_alpha=0.2, reg_lambda=0.2, subsample=0.225;, score=(train=0.444, test=0.173) total time=   0.6s\n",
      "[CV 2/3] END colsample_bynode=0.7, colsample_bytree=0.4, gamma=12.8, learning_rate=0.05, max_depth=7, n_estimators=70, reg_alpha=0.2, reg_lambda=0.2, subsample=0.225;, score=(train=0.423, test=0.262) total time=   0.6s\n",
      "[CV 3/3] END colsample_bynode=0.7, colsample_bytree=0.4, gamma=12.8, learning_rate=0.05, max_depth=7, n_estimators=70, reg_alpha=0.2, reg_lambda=0.2, subsample=0.225;, score=(train=0.395, test=0.325) total time=   0.6s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[CV 1/3] END colsample_bynode=0.7, colsample_bytree=0.3, gamma=25.6, learning_rate=0.05, max_depth=8, n_estimators=60, reg_alpha=0.2, reg_lambda=0.0, subsample=0.225;, score=(train=0.412, test=0.173) total time=   0.5s\n",
      "[CV 2/3] END colsample_bynode=0.7, colsample_bytree=0.3, gamma=25.6, learning_rate=0.05, max_depth=8, n_estimators=60, reg_alpha=0.2, reg_lambda=0.0, subsample=0.225;, score=(train=0.418, test=0.293) total time=   0.6s\n",
      "[CV 3/3] END colsample_bynode=0.7, colsample_bytree=0.3, gamma=25.6, learning_rate=0.05, max_depth=8, n_estimators=60, reg_alpha=0.2, reg_lambda=0.0, subsample=0.225;, score=(train=0.371, test=0.331) total time=   0.5s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[CV 1/3] END colsample_bynode=0.7, colsample_bytree=0.3, gamma=25.6, learning_rate=0.05, max_depth=7, n_estimators=70, reg_alpha=0.2, reg_lambda=0.8, subsample=0.2;, score=(train=0.366, test=0.187) total time=   0.6s\n",
      "[CV 2/3] END colsample_bynode=0.7, colsample_bytree=0.3, gamma=25.6, learning_rate=0.05, max_depth=7, n_estimators=70, reg_alpha=0.2, reg_lambda=0.8, subsample=0.2;, score=(train=0.370, test=0.287) total time=   0.6s\n",
      "[CV 3/3] END colsample_bynode=0.7, colsample_bytree=0.3, gamma=25.6, learning_rate=0.05, max_depth=7, n_estimators=70, reg_alpha=0.2, reg_lambda=0.8, subsample=0.2;, score=(train=0.366, test=0.282) total time=   0.6s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[CV 1/3] END colsample_bynode=0.7, colsample_bytree=0.3, gamma=25.6, learning_rate=0.05, max_depth=5, n_estimators=70, reg_alpha=0.1, reg_lambda=0.1, subsample=0.175;, score=(train=0.313, test=0.178) total time=   0.5s\n",
      "[CV 2/3] END colsample_bynode=0.7, colsample_bytree=0.3, gamma=25.6, learning_rate=0.05, max_depth=5, n_estimators=70, reg_alpha=0.1, reg_lambda=0.1, subsample=0.175;, score=(train=0.344, test=0.263) total time=   0.5s\n",
      "[CV 3/3] END colsample_bynode=0.7, colsample_bytree=0.3, gamma=25.6, learning_rate=0.05, max_depth=5, n_estimators=70, reg_alpha=0.1, reg_lambda=0.1, subsample=0.175;, score=(train=0.284, test=0.297) total time=   0.5s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[CV 1/3] END colsample_bynode=0.7, colsample_bytree=0.3, gamma=12.8, learning_rate=0.05, max_depth=6, n_estimators=90, reg_alpha=0.2, reg_lambda=0.1, subsample=0.225;, score=(train=0.431, test=0.178) total time=   0.6s\n",
      "[CV 2/3] END colsample_bynode=0.7, colsample_bytree=0.3, gamma=12.8, learning_rate=0.05, max_depth=6, n_estimators=90, reg_alpha=0.2, reg_lambda=0.1, subsample=0.225;, score=(train=0.423, test=0.277) total time=   0.6s\n",
      "[CV 3/3] END colsample_bynode=0.7, colsample_bytree=0.3, gamma=12.8, learning_rate=0.05, max_depth=6, n_estimators=90, reg_alpha=0.2, reg_lambda=0.1, subsample=0.225;, score=(train=0.379, test=0.313) total time=   0.6s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[CV 1/3] END colsample_bynode=0.7, colsample_bytree=0.4, gamma=25.6, learning_rate=0.05, max_depth=6, n_estimators=90, reg_alpha=0.2, reg_lambda=0.0, subsample=0.225;, score=(train=0.414, test=0.200) total time=   0.6s\n",
      "[CV 2/3] END colsample_bynode=0.7, colsample_bytree=0.4, gamma=25.6, learning_rate=0.05, max_depth=6, n_estimators=90, reg_alpha=0.2, reg_lambda=0.0, subsample=0.225;, score=(train=0.414, test=0.296) total time=   0.7s\n",
      "[CV 3/3] END colsample_bynode=0.7, colsample_bytree=0.4, gamma=25.6, learning_rate=0.05, max_depth=6, n_estimators=90, reg_alpha=0.2, reg_lambda=0.0, subsample=0.225;, score=(train=0.374, test=0.297) total time=   0.7s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[CV 1/3] END colsample_bynode=0.7, colsample_bytree=0.3, gamma=25.6, learning_rate=0.05, max_depth=8, n_estimators=70, reg_alpha=0.2, reg_lambda=0.1, subsample=0.175;, score=(train=0.423, test=0.168) total time=   0.5s\n",
      "[CV 2/3] END colsample_bynode=0.7, colsample_bytree=0.3, gamma=25.6, learning_rate=0.05, max_depth=8, n_estimators=70, reg_alpha=0.2, reg_lambda=0.1, subsample=0.175;, score=(train=0.410, test=0.333) total time=   0.5s\n",
      "[CV 3/3] END colsample_bynode=0.7, colsample_bytree=0.3, gamma=25.6, learning_rate=0.05, max_depth=8, n_estimators=70, reg_alpha=0.2, reg_lambda=0.1, subsample=0.175;, score=(train=0.396, test=0.333) total time=   0.5s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[CV 1/3] END colsample_bynode=0.7, colsample_bytree=0.4, gamma=25.6, learning_rate=0.05, max_depth=5, n_estimators=70, reg_alpha=0.2, reg_lambda=0.1, subsample=0.175;, score=(train=0.349, test=0.209) total time=   0.4s\n",
      "[CV 2/3] END colsample_bynode=0.7, colsample_bytree=0.4, gamma=25.6, learning_rate=0.05, max_depth=5, n_estimators=70, reg_alpha=0.2, reg_lambda=0.1, subsample=0.175;, score=(train=0.313, test=0.263) total time=   0.5s\n",
      "[CV 3/3] END colsample_bynode=0.7, colsample_bytree=0.4, gamma=25.6, learning_rate=0.05, max_depth=5, n_estimators=70, reg_alpha=0.2, reg_lambda=0.1, subsample=0.175;, score=(train=0.284, test=0.297) total time=   0.5s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[CV 1/3] END colsample_bynode=0.7, colsample_bytree=0.4, gamma=25.6, learning_rate=0.05, max_depth=7, n_estimators=90, reg_alpha=0.2, reg_lambda=0.2, subsample=0.175;, score=(train=0.425, test=0.208) total time=   0.6s\n",
      "[CV 2/3] END colsample_bynode=0.7, colsample_bytree=0.4, gamma=25.6, learning_rate=0.05, max_depth=7, n_estimators=90, reg_alpha=0.2, reg_lambda=0.2, subsample=0.175;, score=(train=0.473, test=0.328) total time=   0.7s\n",
      "[CV 3/3] END colsample_bynode=0.7, colsample_bytree=0.4, gamma=25.6, learning_rate=0.05, max_depth=7, n_estimators=90, reg_alpha=0.2, reg_lambda=0.2, subsample=0.175;, score=(train=0.406, test=0.308) total time=   0.7s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[CV 1/3] END colsample_bynode=0.7, colsample_bytree=0.3, gamma=25.6, learning_rate=0.05, max_depth=8, n_estimators=90, reg_alpha=0.2, reg_lambda=0.4, subsample=0.175;, score=(train=0.416, test=0.187) total time=   0.6s\n",
      "[CV 2/3] END colsample_bynode=0.7, colsample_bytree=0.3, gamma=25.6, learning_rate=0.05, max_depth=8, n_estimators=90, reg_alpha=0.2, reg_lambda=0.4, subsample=0.175;, score=(train=0.445, test=0.318) total time=   0.6s\n",
      "[CV 3/3] END colsample_bynode=0.7, colsample_bytree=0.3, gamma=25.6, learning_rate=0.05, max_depth=8, n_estimators=90, reg_alpha=0.2, reg_lambda=0.4, subsample=0.175;, score=(train=0.395, test=0.333) total time=   0.6s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[CV 1/3] END colsample_bynode=0.7, colsample_bytree=0.4, gamma=25.6, learning_rate=0.05, max_depth=8, n_estimators=90, reg_alpha=0.2, reg_lambda=0.0, subsample=0.175;, score=(train=0.461, test=0.212) total time=   0.7s\n",
      "[CV 2/3] END colsample_bynode=0.7, colsample_bytree=0.4, gamma=25.6, learning_rate=0.05, max_depth=8, n_estimators=90, reg_alpha=0.2, reg_lambda=0.0, subsample=0.175;, score=(train=0.426, test=0.321) total time=   0.7s\n",
      "[CV 3/3] END colsample_bynode=0.7, colsample_bytree=0.4, gamma=25.6, learning_rate=0.05, max_depth=8, n_estimators=90, reg_alpha=0.2, reg_lambda=0.0, subsample=0.175;, score=(train=0.454, test=0.331) total time=   0.9s\n",
      "Test\n",
      "\n",
      "[[3116   93]\n",
      " [  36   14]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98      3209\n",
      "           1       0.13      0.28      0.18        50\n",
      "\n",
      "    accuracy                           0.96      3259\n",
      "   macro avg       0.56      0.63      0.58      3259\n",
      "weighted avg       0.98      0.96      0.97      3259\n",
      "\n",
      "0.14644351464435146\n",
      "Train\n",
      "\n",
      "[[9385  239]\n",
      " [  53   98]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.98      9624\n",
      "           1       0.29      0.65      0.40       151\n",
      "\n",
      "    accuracy                           0.97      9775\n",
      "   macro avg       0.64      0.81      0.69      9775\n",
      "weighted avg       0.98      0.97      0.98      9775\n",
      "\n",
      "0.3268845897264843\n"
     ]
    }
   ],
   "source": [
    "#TUNING ROUND 2\n",
    "param_grid = {'gamma':[6.4, 12.8, 25.6, 51.2],\n",
    "              'learning_rate':[0.05, 0.075, 0.1],\n",
    "              'max_depth':[5, 6, 7, 8],\n",
    "              'n_estimators':[60, 70, 80, 90, 100],\n",
    "              'subsample':[0.175, 0.2, 0.225],\n",
    "              'colsample_bynode':[0.4, 0.5, 0.6, 0.7, 0.8],\n",
    "              'colsample_bytree':[0.2, 0.3, 0.4],\n",
    "              'reg_alpha':[0, 0.1, 0.2, 0.4, 0.8],\n",
    "              'reg_lambda':[0, 0.1, 0.2, 0.4, 0.8]}\n",
    "\n",
    "gcvj = np.cumsum([len(x) for x in param_grid.values()])[-1]\n",
    "bcvj = int(gcvj)\n",
    "\n",
    "xgbc = xgb.XGBClassifier(objective='binary:logistic',\n",
    "                          booster='gbtree',\n",
    "                          scale_pos_weight=63,\n",
    "                          eval_metric='auc')\n",
    "\n",
    "clf = BayesSearchCV(estimator=xgbc, search_spaces=param_grid, n_iter=bcvj, scoring='f1', cv=3, return_train_score=True, verbose=3)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "df2 = pd.DataFrame(clf.cv_results_)\n",
    "\n",
    "train_pred = clf.predict(X_train)\n",
    "test_pred = clf.predict(X_test)\n",
    "\n",
    "print('Test\\n')\n",
    "print(confusion_matrix(y_test, test_pred))\n",
    "print(classification_report(y_test,test_pred))\n",
    "print(metrics.fbeta_score(y_test, test_pred, beta=0.5))\n",
    "print('Train\\n')\n",
    "print(confusion_matrix(y_train, train_pred))\n",
    "print(classification_report(y_train,train_pred))\n",
    "print(metrics.fbeta_score(y_train, train_pred, beta=0.5))\n",
    "\n",
    "bp2 = clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('colsample_bynode', 0.7),\n",
       "             ('colsample_bytree', 0.4),\n",
       "             ('gamma', 25.6),\n",
       "             ('learning_rate', 0.05),\n",
       "             ('max_depth', 8),\n",
       "             ('n_estimators', 90),\n",
       "             ('reg_alpha', 0.2),\n",
       "             ('reg_lambda', 0.0),\n",
       "             ('subsample', 0.175)])"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_df2 = df2.sort_values(by='rank_test_score')\n",
    "sorted_df2.to_csv('stats_round2.csv',index=False)\n",
    "bp2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-auc:0.70764\n",
      "[2]\tvalidation_0-auc:0.72812\n",
      "[4]\tvalidation_0-auc:0.71587\n",
      "[6]\tvalidation_0-auc:0.74456\n",
      "[8]\tvalidation_0-auc:0.81324\n",
      "[10]\tvalidation_0-auc:0.81792\n",
      "[12]\tvalidation_0-auc:0.81677\n",
      "[14]\tvalidation_0-auc:0.81264\n",
      "[16]\tvalidation_0-auc:0.83711\n",
      "[18]\tvalidation_0-auc:0.83040\n",
      "[20]\tvalidation_0-auc:0.83349\n",
      "[22]\tvalidation_0-auc:0.84161\n",
      "[24]\tvalidation_0-auc:0.83646\n",
      "[26]\tvalidation_0-auc:0.84944\n",
      "[28]\tvalidation_0-auc:0.84461\n",
      "[30]\tvalidation_0-auc:0.84551\n",
      "[32]\tvalidation_0-auc:0.86557\n",
      "[34]\tvalidation_0-auc:0.86633\n",
      "[36]\tvalidation_0-auc:0.87204\n",
      "[38]\tvalidation_0-auc:0.87726\n",
      "[40]\tvalidation_0-auc:0.88039\n",
      "[42]\tvalidation_0-auc:0.87864\n",
      "[44]\tvalidation_0-auc:0.88149\n",
      "[46]\tvalidation_0-auc:0.88559\n",
      "[48]\tvalidation_0-auc:0.88522\n",
      "[50]\tvalidation_0-auc:0.88274\n",
      "[52]\tvalidation_0-auc:0.88164\n",
      "[54]\tvalidation_0-auc:0.88659\n",
      "[56]\tvalidation_0-auc:0.88735\n",
      "[58]\tvalidation_0-auc:0.88842\n",
      "[60]\tvalidation_0-auc:0.89091\n",
      "[62]\tvalidation_0-auc:0.89078\n",
      "[64]\tvalidation_0-auc:0.88719\n",
      "[66]\tvalidation_0-auc:0.88808\n",
      "[68]\tvalidation_0-auc:0.88555\n",
      "[70]\tvalidation_0-auc:0.88527\n",
      "[72]\tvalidation_0-auc:0.88150\n",
      "[74]\tvalidation_0-auc:0.88090\n",
      "[76]\tvalidation_0-auc:0.88315\n",
      "[78]\tvalidation_0-auc:0.88153\n",
      "[80]\tvalidation_0-auc:0.88236\n",
      "[82]\tvalidation_0-auc:0.88044\n",
      "[84]\tvalidation_0-auc:0.87910\n",
      "[86]\tvalidation_0-auc:0.88085\n",
      "[88]\tvalidation_0-auc:0.88318\n",
      "[89]\tvalidation_0-auc:0.88206\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-101 {color: black;background-color: white;}#sk-container-id-101 pre{padding: 0;}#sk-container-id-101 div.sk-toggleable {background-color: white;}#sk-container-id-101 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-101 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-101 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-101 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-101 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-101 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-101 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-101 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-101 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-101 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-101 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-101 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-101 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-101 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-101 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-101 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-101 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-101 div.sk-item {position: relative;z-index: 1;}#sk-container-id-101 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-101 div.sk-item::before, #sk-container-id-101 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-101 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-101 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-101 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-101 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-101 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-101 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-101 div.sk-label-container {text-align: center;}#sk-container-id-101 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-101 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-101\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=0.5, colsample_bytree=0.4,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=&#x27;auc&#x27;, feature_types=None, gamma=20, gpu_id=-1,\n",
       "              grow_policy=&#x27;depthwise&#x27;, importance_type=None,\n",
       "              interaction_constraints=&#x27;&#x27;, learning_rate=0.1, max_bin=256,\n",
       "              max_cat_threshold=64, max_cat_to_onehot=4, max_delta_step=0,\n",
       "              max_depth=8, max_leaves=0, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints=&#x27;()&#x27;, n_estimators=90, n_jobs=0,\n",
       "              num_parallel_tree=1, predictor=&#x27;auto&#x27;, random_state=0, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-101\" type=\"checkbox\" checked><label for=\"sk-estimator-id-101\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=0.5, colsample_bytree=0.4,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=&#x27;auc&#x27;, feature_types=None, gamma=20, gpu_id=-1,\n",
       "              grow_policy=&#x27;depthwise&#x27;, importance_type=None,\n",
       "              interaction_constraints=&#x27;&#x27;, learning_rate=0.1, max_bin=256,\n",
       "              max_cat_threshold=64, max_cat_to_onehot=4, max_delta_step=0,\n",
       "              max_depth=8, max_leaves=0, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints=&#x27;()&#x27;, n_estimators=90, n_jobs=0,\n",
       "              num_parallel_tree=1, predictor=&#x27;auto&#x27;, random_state=0, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=0.5, colsample_bytree=0.4,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric='auc', feature_types=None, gamma=20, gpu_id=-1,\n",
       "              grow_policy='depthwise', importance_type=None,\n",
       "              interaction_constraints='', learning_rate=0.1, max_bin=256,\n",
       "              max_cat_threshold=64, max_cat_to_onehot=4, max_delta_step=0,\n",
       "              max_depth=8, max_leaves=0, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints='()', n_estimators=90, n_jobs=0,\n",
       "              num_parallel_tree=1, predictor='auto', random_state=0, ...)"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_xgb = xgb.XGBClassifier(scale_pos_weight=63, max_depth=8,learning_rate=0.1, n_estimators=90, objective='binary:logistic',\n",
    "                         booster='gbtree', subsample=0.175, eval_metric='auc', colsample_bynode=.5,colsample_bytree=.4,\n",
    "                         reg_alpha=0.2, reg_lambda=0.0, gamma=20)\n",
    "\n",
    "eval_set = [(X_test,y_test)]\n",
    "clf_xgb.fit(X_train, y_train, verbose=2, eval_set=eval_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test\n",
      "\n",
      "[[3146   63]\n",
      " [  37   13]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.98      3209\n",
      "           1       0.17      0.26      0.21        50\n",
      "\n",
      "    accuracy                           0.97      3259\n",
      "   macro avg       0.58      0.62      0.60      3259\n",
      "weighted avg       0.98      0.97      0.97      3259\n",
      "\n",
      "0.18361581920903955\n",
      "Train\n",
      "\n",
      "[[9464  160]\n",
      " [  31  120]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99      9624\n",
      "           1       0.43      0.79      0.56       151\n",
      "\n",
      "    accuracy                           0.98      9775\n",
      "   macro avg       0.71      0.89      0.77      9775\n",
      "weighted avg       0.99      0.98      0.98      9775\n",
      "\n",
      "0.47206923682140045\n"
     ]
    }
   ],
   "source": [
    "train_pred = clf_xgb.predict(X_train)\n",
    "test_pred = clf_xgb.predict(X_test)\n",
    "\n",
    "print('Test\\n')\n",
    "print(confusion_matrix(y_test, test_pred))\n",
    "print(classification_report(y_test,test_pred))\n",
    "print(metrics.fbeta_score(y_test, test_pred, beta=0.5))\n",
    "print('Train\\n')\n",
    "print(confusion_matrix(y_train, train_pred))\n",
    "print(classification_report(y_train,train_pred))\n",
    "print(metrics.fbeta_score(y_train, train_pred, beta=0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "476ebe9d743668a98ca8291e5354fc0c9bf75843f5002862f070b4b496e7f9e5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
